{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11420152,"sourceType":"datasetVersion","datasetId":7152221}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom skimage import filters, morphology, measure\nfrom tqdm import tqdm\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:39:54.671104Z","iopub.execute_input":"2025-04-27T13:39:54.671987Z","iopub.status.idle":"2025-04-27T13:40:03.697240Z","shell.execute_reply.started":"2025-04-27T13:39:54.671944Z","shell.execute_reply":"2025-04-27T13:40:03.696574Z"}},"outputs":[{"name":"stderr","text":"2025-04-27 13:39:56.245240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745761196.452576     257 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745761196.514484     257 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Use Mixed Precision (save VRAM)\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\nprint(\"mixed precision enabled.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:03.698369Z","iopub.execute_input":"2025-04-27T13:40:03.698848Z","iopub.status.idle":"2025-04-27T13:40:03.703452Z","shell.execute_reply.started":"2025-04-27T13:40:03.698828Z","shell.execute_reply":"2025-04-27T13:40:03.702747Z"}},"outputs":[{"name":"stdout","text":"mixed precision enabled.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Set random seeds for reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:03.704156Z","iopub.execute_input":"2025-04-27T13:40:03.704371Z","iopub.status.idle":"2025-04-27T13:40:03.717267Z","shell.execute_reply.started":"2025-04-27T13:40:03.704354Z","shell.execute_reply":"2025-04-27T13:40:03.716449Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Parameters\nIMG_SIZE = 256  # Input size for U-Net\nBATCH_SIZE = 8\nEPOCHS = 2\nDATASET_ROOT = '/kaggle/input/preprocessed-mammo-splits'\nOUTPUT_DIR = './cell_roi_extracted'\nSEGMENTATION_MODEL_PATH = './cell_unet_model.keras'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:03.719143Z","iopub.execute_input":"2025-04-27T13:40:03.719673Z","iopub.status.idle":"2025-04-27T13:40:03.942660Z","shell.execute_reply.started":"2025-04-27T13:40:03.719653Z","shell.execute_reply":"2025-04-27T13:40:03.941993Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Create output directory if it doesn't exist\nos.makedirs(OUTPUT_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:03.943417Z","iopub.execute_input":"2025-04-27T13:40:03.943718Z","iopub.status.idle":"2025-04-27T13:40:03.958403Z","shell.execute_reply.started":"2025-04-27T13:40:03.943697Z","shell.execute_reply":"2025-04-27T13:40:03.957775Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define custom IoU metric\ndef iou_metric(y_true, y_pred):\n    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n    return intersection / (union + tf.keras.backend.epsilon())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:03.959047Z","iopub.execute_input":"2025-04-27T13:40:03.959311Z","iopub.status.idle":"2025-04-27T13:40:03.973589Z","shell.execute_reply.started":"2025-04-27T13:40:03.959293Z","shell.execute_reply":"2025-04-27T13:40:03.972799Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Build U-Net model for cell segmentation\ndef build_unet_model(input_size=(IMG_SIZE, IMG_SIZE, 1)):\n    inputs = Input(input_size)\n    \n    # Encoder (Downsampling)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n    \n    # Bridge\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n    \n    # Decoder (Upsampling)\n    up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n    merge6 = concatenate([drop4, up6], axis=3)\n    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n    \n    up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n    merge7 = concatenate([conv3, up7], axis=3)\n    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n    \n    up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n    merge8 = concatenate([conv2, up8], axis=3)\n    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n    \n    up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n    merge9 = concatenate([conv1, up9], axis=3)\n    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n    \n    # Output layer - sigmoid for binary segmentation\n    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n    \n    model = Model(inputs, outputs)\n    model.compile(optimizer=Adam(learning_rate=1e-4), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy', iou_metric])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:03.974358Z","iopub.execute_input":"2025-04-27T13:40:03.974611Z","iopub.status.idle":"2025-04-27T13:40:03.991781Z","shell.execute_reply.started":"2025-04-27T13:40:03.974586Z","shell.execute_reply":"2025-04-27T13:40:03.991123Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def load_preprocessed_data():\n    train_data = np.load(os.path.join(DATASET_ROOT, 'train_data.npz'))\n    val_data = np.load(os.path.join(DATASET_ROOT, 'val_data.npz'))\n    test_data = np.load(os.path.join(DATASET_ROOT, 'test_data.npz'))\n    \n    X_train, y_train = train_data['X'], train_data['y']\n    X_val, y_val = val_data['X'], val_data['y']\n    X_test, y_test = test_data['X'], test_data['y']\n    \n    # Ensure images are in grayscale for segmentation\n    if X_train.shape[-1] == 3:\n        X_train = np.mean(X_train, axis=-1, keepdims=True)\n        X_val = np.mean(X_val, axis=-1, keepdims=True)\n        X_test = np.mean(X_test, axis=-1, keepdims=True)\n    \n    print(f\"Loaded data shapes: Train {X_train.shape}, Val {X_val.shape}, Test {X_test.shape}\")\n    return X_train, y_train, X_val, y_val, X_test, y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:03.992583Z","iopub.execute_input":"2025-04-27T13:40:03.992843Z","iopub.status.idle":"2025-04-27T13:40:04.008847Z","shell.execute_reply.started":"2025-04-27T13:40:03.992794Z","shell.execute_reply":"2025-04-27T13:40:04.008249Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Generate masks for cell images using adaptive thresholding\ndef generate_cell_masks(images):\n    masks = []\n    for img in tqdm(images, desc=\"Generating cell masks\"):\n        # Convert to single channel and scale to 0-255\n        img_2d = img.squeeze()\n        img_2d = (img_2d * 255).astype(np.uint8)\n        \n        # Apply adaptive thresholding\n        binary = cv2.adaptiveThreshold(\n            img_2d, \n            255, \n            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n            cv2.THRESH_BINARY_INV, \n            11, \n            2\n        )\n        \n        # Clean up the mask with morphological operations\n        kernel = np.ones((3, 3), np.uint8)\n        opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n        \n        # Remove small objects (noise)\n        nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(opening, connectivity=8)\n        sizes = stats[1:, -1]\n        min_size = 30  # Minimum size of cell objects\n        \n        # Clean mask\n        clean_mask = np.zeros_like(output)\n        for i in range(1, nb_components):\n            if sizes[i - 1] >= min_size:\n                clean_mask[output == i] = 1\n        \n        # Add channel dimension back\n        masks.append(clean_mask.reshape(img.shape))\n    \n    return np.array(masks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:04.009641Z","iopub.execute_input":"2025-04-27T13:40:04.010304Z","iopub.status.idle":"2025-04-27T13:40:04.028577Z","shell.execute_reply.started":"2025-04-27T13:40:04.010278Z","shell.execute_reply":"2025-04-27T13:40:04.027959Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Extract ROI using segmentation masks\ndef extract_roi(images, masks):\n    roi_images = []\n    \n    for image, mask in zip(images, masks):\n        # Apply mask to original image\n        roi = image * mask\n        roi_images.append(roi)\n    \n    return np.array(roi_images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:04.030620Z","iopub.execute_input":"2025-04-27T13:40:04.030890Z","iopub.status.idle":"2025-04-27T13:40:04.045370Z","shell.execute_reply.started":"2025-04-27T13:40:04.030873Z","shell.execute_reply":"2025-04-27T13:40:04.044643Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Process individual cells for feature extraction\ndef extract_cell_features(image, mask):\n    # Label individual cells\n    labeled_mask = measure.label(mask.squeeze())\n    props = measure.regionprops(labeled_mask)\n    \n    cell_features = []\n    for prop in props:\n        # Get bounding box\n        min_row, min_col, max_row, max_col = prop.bbox\n        \n        # Extract cell\n        cell = image.squeeze()[min_row:max_row, min_col:max_col]\n        \n        # Calculate features\n        mean_intensity = prop.mean_intensity\n        area = prop.area\n        perimeter = prop.perimeter\n        eccentricity = prop.eccentricity\n        \n        cell_features.append({\n            'cell_image': cell,\n            'mean_intensity': mean_intensity,\n            'area': area,\n            'perimeter': perimeter,\n            'eccentricity': eccentricity\n        })\n    \n    return cell_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:04.046326Z","iopub.execute_input":"2025-04-27T13:40:04.046695Z","iopub.status.idle":"2025-04-27T13:40:04.059832Z","shell.execute_reply.started":"2025-04-27T13:40:04.046675Z","shell.execute_reply":"2025-04-27T13:40:04.058995Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Save some example segmentation results for visualization\ndef save_segmentation_examples(images, masks, rois, filename=\"cell_segmentation_examples.png\"):\n    fig, axes = plt.subplots(5, 3, figsize=(15, 25))\n    \n    for i in range(5):\n        # Original image\n        axes[i, 0].imshow(images[i].squeeze(), cmap='gray')\n        axes[i, 0].set_title('Original Cell Image')\n        axes[i, 0].axis('off')\n        \n        # Mask\n        axes[i, 1].imshow(masks[i].squeeze(), cmap='gray')\n        axes[i, 1].set_title('Cell Segmentation Mask')\n        axes[i, 1].axis('off')\n        \n        # ROI\n        axes[i, 2].imshow(rois[i].squeeze(), cmap='gray')\n        axes[i, 2].set_title('Extracted Cell ROI')\n        axes[i, 2].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, filename))\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:04.060731Z","iopub.execute_input":"2025-04-27T13:40:04.061008Z","iopub.status.idle":"2025-04-27T13:40:04.077598Z","shell.execute_reply.started":"2025-04-27T13:40:04.060989Z","shell.execute_reply":"2025-04-27T13:40:04.076956Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Create a visualization showing cell segmentation outlines\ndef save_cell_contour_visualization(images, masks, filename=\"cell_contours.png\"):\n    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n    \n    for i in range(min(9, len(images))):\n        row, col = i // 3, i % 3\n        \n        # Get original image\n        img = images[i].squeeze()\n        mask = masks[i].squeeze()\n        \n        # Create RGB visualization\n        img_rgb = np.stack([img, img, img], axis=-1)\n        \n        # Find contours\n        contours, _ = cv2.findContours(\n            (mask * 255).astype(np.uint8),\n            cv2.RETR_EXTERNAL,\n            cv2.CHAIN_APPROX_SIMPLE\n        )\n        \n        # Draw contours on RGB image\n        cv2.drawContours(img_rgb, contours, -1, (0, 1, 0), 1)  # Green contours\n        \n        # Display\n        axes[row, col].imshow(img_rgb)\n        axes[row, col].set_title(f'Cell Sample {i+1}')\n        axes[row, col].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, filename))\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:04.078589Z","iopub.execute_input":"2025-04-27T13:40:04.078929Z","iopub.status.idle":"2025-04-27T13:40:04.093296Z","shell.execute_reply.started":"2025-04-27T13:40:04.078909Z","shell.execute_reply":"2025-04-27T13:40:04.092515Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Main function for segmentation and ROI extraction\ndef main():\n    # Load preprocessed data\n    print(\"Loading preprocessed data...\")\n    X_train, y_train, X_val, y_val, X_test, y_test = load_preprocessed_data()\n    \n    # Create or load U-Net model\n    if os.path.exists(SEGMENTATION_MODEL_PATH):\n        print(f\"Loading existing U-Net model from {SEGMENTATION_MODEL_PATH}\")\n        model = tf.keras.models.load_model(SEGMENTATION_MODEL_PATH)\n    else:\n        print(\"Building and training U-Net segmentation model...\")\n        model = build_unet_model(input_size=(IMG_SIZE, IMG_SIZE, 1))\n        \n        # Generate training masks\n        print(\"Generating cell masks...\")\n        train_masks = generate_cell_masks(X_train)\n        val_masks = generate_cell_masks(X_val)\n        \n        # Set up callbacks\n        callbacks = [\n            ModelCheckpoint(SEGMENTATION_MODEL_PATH, save_best_only=True, monitor='val_loss'),\n            EarlyStopping(patience=10, monitor='val_loss'),\n            ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-6, monitor='val_loss')\n        ]\n        \n        # Train the model\n        history = model.fit(\n            X_train, train_masks,\n            batch_size=BATCH_SIZE,\n            epochs=EPOCHS,\n            validation_data=(X_val, val_masks),\n            callbacks=callbacks\n        )\n        \n        # Plot training history\n        plt.figure(figsize=(12, 4))\n        plt.subplot(1, 2, 1)\n        plt.plot(history.history['loss'], label='Train Loss')\n        plt.plot(history.history['val_loss'], label='Validation Loss')\n        plt.title('Loss')\n        plt.legend()\n        \n        plt.subplot(1, 2, 2)\n        plt.plot(history.history['accuracy'], label='Train Accuracy')\n        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n        plt.title('Accuracy')\n        plt.legend()\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(OUTPUT_DIR, 'cell_training_history.png'))\n        plt.close()\n    \n    # Predict segmentation masks\n    print(\"Predicting cell segmentation masks...\")\n    train_pred_masks = model.predict(X_train, verbose=1, batch_size=BATCH_SIZE)\n    val_pred_masks = model.predict(X_val, verbose=1, batch_size=BATCH_SIZE)\n    test_pred_masks = model.predict(X_test, verbose=1, batch_size=BATCH_SIZE)\n    \n    # Convert predictions to binary masks\n    threshold = 0.5\n    train_binary_masks = (train_pred_masks > threshold).astype(np.float32)\n    val_binary_masks = (val_pred_masks > threshold).astype(np.float32)\n    test_binary_masks = (test_pred_masks > threshold).astype(np.float32)\n    \n    # Post-process the binary masks to clean them up\n    for i in range(len(train_binary_masks)):\n        # Remove small objects\n        binary = morphology.remove_small_objects(train_binary_masks[i].squeeze().astype(bool), min_size=30)\n        # Fill holes\n        binary = morphology.binary_closing(binary, morphology.disk(3))\n        binary = morphology.binary_fill_holes(binary)\n        train_binary_masks[i] = binary.astype(np.float32).reshape(train_binary_masks[i].shape)\n    \n    for i in range(len(val_binary_masks)):\n        binary = morphology.remove_small_objects(val_binary_masks[i].squeeze().astype(bool), min_size=30)\n        binary = morphology.binary_closing(binary, morphology.disk(3))\n        binary = morphology.binary_fill_holes(binary)\n        val_binary_masks[i] = binary.astype(np.float32).reshape(val_binary_masks[i].shape)\n    \n    for i in range(len(test_binary_masks)):\n        binary = morphology.remove_small_objects(test_binary_masks[i].squeeze().astype(bool), min_size=30)\n        binary = morphology.binary_closing(binary, morphology.disk(3))\n        binary = morphology.binary_fill_holes(binary)\n        test_binary_masks[i] = binary.astype(np.float32).reshape(test_binary_masks[i].shape)\n    \n    # Extract ROIs\n    print(\"Extracting cell ROIs...\")\n    train_roi = extract_roi(X_train, train_binary_masks)\n    val_roi = extract_roi(X_val, val_binary_masks)\n    test_roi = extract_roi(X_test, test_binary_masks)\n    \n    # Save ROI extracted datasets\n    print(\"Saving cell ROI extracted datasets...\")\n    np.savez_compressed(os.path.join(OUTPUT_DIR, 'cell_roi_train_data.npz'), X=train_roi, y=y_train)\n    np.savez_compressed(os.path.join(OUTPUT_DIR, 'cell_roi_val_data.npz'), X=val_roi, y=y_val)\n    np.savez_compressed(os.path.join(OUTPUT_DIR, 'cell_roi_test_data.npz'), X=test_roi, y=y_test)\n    \n    # Save segmentation examples\n    print(\"Saving cell segmentation examples...\")\n    save_segmentation_examples(X_train[:5], train_binary_masks[:5], train_roi[:5], \"train_cell_segmentation.png\")\n    save_segmentation_examples(X_val[:5], val_binary_masks[:5], val_roi[:5], \"val_cell_segmentation.png\")\n    save_segmentation_examples(X_test[:5], test_binary_masks[:5], test_roi[:5], \"test_cell_segmentation.png\")\n    \n    # Save contour visualization\n    save_cell_contour_visualization(X_train[:9], train_binary_masks[:9], \"cell_contours_train.png\")\n    \n    # Calculate and save segmentation metrics\n    print(\"Calculating segmentation metrics...\")\n    \n    # For demonstration, we'll use a small sample of the validation masks\n    sample_size = min(100, len(val_binary_masks))\n    dice_scores = []\n    iou_scores = []\n    \n    for i in range(sample_size):\n        pred = val_binary_masks[i].squeeze().astype(np.bool_)\n        true = generate_cell_masks(val_pred_masks[i:i+1])[0].squeeze().astype(np.bool_)\n        \n        intersection = np.logical_and(pred, true).sum()\n        union = np.logical_or(pred, true).sum()\n        \n        # IoU\n        iou = intersection / (union + 1e-7)\n        iou_scores.append(iou)\n        \n        # Dice coefficient\n        dice = (2 * intersection) / (pred.sum() + true.sum() + 1e-7)\n        dice_scores.append(dice)\n    \n    # Save metrics\n    with open(os.path.join(OUTPUT_DIR, 'segmentation_metrics.txt'), 'w') as f:\n        f.write(f\"Mean IoU: {np.mean(iou_scores):.4f}\\n\")\n        f.write(f\"Mean Dice: {np.mean(dice_scores):.4f}\\n\")\n    \n    print(\"Cell ROI extraction complete! Results saved to:\", OUTPUT_DIR)\n    print(\"You can now use the extracted ROIs for your transfer learning hybrid approach.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:04.094457Z","iopub.execute_input":"2025-04-27T13:40:04.094771Z","iopub.status.idle":"2025-04-27T13:40:04.114453Z","shell.execute_reply.started":"2025-04-27T13:40:04.094745Z","shell.execute_reply":"2025-04-27T13:40:04.113823Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:40:04.115474Z","iopub.execute_input":"2025-04-27T13:40:04.115939Z","execution_failed":"2025-04-27T13:41:30.390Z"}},"outputs":[{"name":"stdout","text":"Loading preprocessed data...\nLoaded data shapes: Train (17755, 224, 224, 1), Val (3134, 224, 224, 1), Test (3687, 224, 224, 1)\nBuilding and training U-Net segmentation model...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1745761239.734669     257 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Generating cell masks...\n","output_type":"stream"},{"name":"stderr","text":"Generating cell masks: 100%|██████████| 17755/17755 [00:25<00:00, 698.84it/s]\nGenerating cell masks: 100%|██████████| 3134/3134 [00:03<00:00, 815.09it/s]\n","output_type":"stream"}],"execution_count":null}]}