{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11420152,"sourceType":"datasetVersion","datasetId":7152221}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, EfficientNetB3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import KFold\nimport pickle\nimport collections\nfrom sklearn.metrics import (\n    accuracy_score, roc_auc_score, precision_score, recall_score,\n    f1_score, confusion_matrix, roc_curve\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:48:17.348860Z","iopub.execute_input":"2025-04-23T09:48:17.349467Z","iopub.status.idle":"2025-04-23T09:48:17.354293Z","shell.execute_reply.started":"2025-04-23T09:48:17.349444Z","shell.execute_reply":"2025-04-23T09:48:17.353516Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Use Mixed Precision (save VRAM)\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\nprint(\"mixed precision enabled.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:48:18.979126Z","iopub.execute_input":"2025-04-23T09:48:18.979420Z","iopub.status.idle":"2025-04-23T09:48:18.983657Z","shell.execute_reply.started":"2025-04-23T09:48:18.979388Z","shell.execute_reply":"2025-04-23T09:48:18.983080Z"}},"outputs":[{"name":"stdout","text":"mixed precision enabled.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Load Preprocessed Data --- balanced checked\nDATA_PATH = \"/kaggle/input/preprocessed-mammo-splits\"  \ntrain = np.load(os.path.join(DATA_PATH, \"train_data.npz\"))\nval = np.load(os.path.join(DATA_PATH, \"val_data.npz\"))\ntest = np.load(os.path.join(DATA_PATH, \"test_data.npz\"))\n\nX_train, y_train = train[\"X\"], train[\"y\"]\nX_val, y_val = val[\"X\"], val[\"y\"]\nX_test, y_test = test[\"X\"], test[\"y\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:48:20.818074Z","iopub.execute_input":"2025-04-23T09:48:20.818355Z","iopub.status.idle":"2025-04-23T09:48:47.051541Z","shell.execute_reply.started":"2025-04-23T09:48:20.818333Z","shell.execute_reply":"2025-04-23T09:48:47.050978Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(f\"X_train range: [{X_train.min()}, {X_train.max()}]\")\nprint(f\"X_val range: [{X_val.min()}, {X_val.max()}]\")\nprint(f\"X_test range: [{X_test.min()}, {X_test.max()}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:48:47.052657Z","iopub.execute_input":"2025-04-23T09:48:47.052940Z","iopub.status.idle":"2025-04-23T09:48:49.307547Z","shell.execute_reply.started":"2025-04-23T09:48:47.052920Z","shell.execute_reply":"2025-04-23T09:48:49.306881Z"}},"outputs":[{"name":"stdout","text":"X_train range: [0.0, 1.0]\nX_val range: [0.0, 1.0]\nX_test range: [0.0, 1.0]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Compute Class Weights\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(zip(np.unique(y_train), class_weights))\nprint(\"Class Weights:\", class_weight_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:48:55.889966Z","iopub.execute_input":"2025-04-23T09:48:55.890216Z","iopub.status.idle":"2025-04-23T09:48:55.899027Z","shell.execute_reply.started":"2025-04-23T09:48:55.890200Z","shell.execute_reply":"2025-04-23T09:48:55.898295Z"}},"outputs":[{"name":"stdout","text":"Class Weights: {0: 1.1308917197452228, 1: 0.8962645128722867}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Expand dims because TF expects (H, W, 1) from (H, W)\nX_train = X_train[..., np.newaxis].astype(\"float32\")\nX_val = X_val[..., np.newaxis].astype(\"float32\")\nX_test = X_test[..., np.newaxis].astype(\"float32\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:48:58.056598Z","iopub.execute_input":"2025-04-23T09:48:58.057185Z","iopub.status.idle":"2025-04-23T09:48:59.932567Z","shell.execute_reply.started":"2025-04-23T09:48:58.057161Z","shell.execute_reply":"2025-04-23T09:48:59.931757Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Print data shapes\nprint(f\"Training data shape: {X_train.shape}, Labels: {y_train.shape}\")\nprint(f\"Validation data shape: {X_val.shape}, Labels: {y_val.shape}\")\nprint(f\"Test data shape: {X_test.shape}, Labels: {y_test.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:06.278466Z","iopub.execute_input":"2025-04-23T09:49:06.279045Z","iopub.status.idle":"2025-04-23T09:49:06.283311Z","shell.execute_reply.started":"2025-04-23T09:49:06.279022Z","shell.execute_reply":"2025-04-23T09:49:06.282576Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (17755, 224, 224, 1, 1), Labels: (17755,)\nValidation data shape: (3134, 224, 224, 1, 1), Labels: (3134,)\nTest data shape: (3687, 224, 224, 1, 1), Labels: (3687,)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Enhanced data augmentation\ndef convert_to_rgb(image, label):\n    image_rgb = tf.image.grayscale_to_rgb(image)  \n    image_rgb = tf.squeeze(image_rgb) \n    return image_rgb, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:09.952051Z","iopub.execute_input":"2025-04-23T09:49:09.952290Z","iopub.status.idle":"2025-04-23T09:49:09.956064Z","shell.execute_reply.started":"2025-04-23T09:49:09.952275Z","shell.execute_reply":"2025-04-23T09:49:09.955345Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def augment(image, label):\n    # Random rotation (0-15 degrees)\n    angle = tf.random.uniform([], -0.26, 0.26)  # ~15 degrees in radians\n    image = tf.image.rot90(image, k=tf.cast(angle * 2 / 3.14159, tf.int32))\n    \n    # Random flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    # Random brightness/contrast adjustments\n    image = tf.image.random_brightness(image, 0.2)\n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    \n    # Random zoom (crop and resize)\n    zoom_factor = tf.random.uniform([], 0.8, 1.0, dtype=tf.float32)\n    h, w = tf.shape(image)[0], tf.shape(image)[1]\n    crop_size_h = tf.cast(tf.cast(h, tf.float32) * zoom_factor, tf.int32)\n    crop_size_w = tf.cast(tf.cast(w, tf.float32) * zoom_factor, tf.int32)\n    \n    # Ensure crop dimensions don't exceed image dimensions\n    crop_size_h = tf.minimum(crop_size_h, h)\n    crop_size_w = tf.minimum(crop_size_w, w)\n    \n    image = tf.image.random_crop(image, size=[crop_size_h, crop_size_w, 3])\n    image = tf.image.resize(image, [224, 224])\n    \n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:11.576056Z","iopub.execute_input":"2025-04-23T09:49:11.576750Z","iopub.status.idle":"2025-04-23T09:49:11.582630Z","shell.execute_reply.started":"2025-04-23T09:49:11.576725Z","shell.execute_reply":"2025-04-23T09:49:11.581860Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Create datasets\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\ntest_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\n# Apply preprocessing and augmentation\ntrain_ds = (\n    train_ds.shuffle(1024)\n    .map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .map(augment, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\nval_ds = (\n    val_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\ntest_ds = (\n    test_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:12.598067Z","iopub.execute_input":"2025-04-23T09:49:12.598690Z","iopub.status.idle":"2025-04-23T09:49:25.966140Z","shell.execute_reply.started":"2025-04-23T09:49:12.598665Z","shell.execute_reply":"2025-04-23T09:49:25.965127Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745401754.908008      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def build_improved_model(base_model_fn, name=\"model\", lr=1e-4):\n    base_model = base_model_fn(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n    # Initially freeze the base model\n    base_model.trainable = False\n    \n    inputs = Input(shape=(224, 224, 3))\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    \n    # Enhanced architecture with more layers\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    \n    outputs = Dense(1, activation='sigmoid', dtype='float32')(x)\n    \n    model = Model(inputs, outputs, name=name)\n    \n    # Use simple float learning rate instead of schedule\n    model.compile(\n        optimizer=Adam(learning_rate=lr),  # Simple float learning rate\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy', \n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    \n    return model, base_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:25.967210Z","iopub.execute_input":"2025-04-23T09:49:25.967463Z","iopub.status.idle":"2025-04-23T09:49:25.973849Z","shell.execute_reply.started":"2025-04-23T09:49:25.967445Z","shell.execute_reply":"2025-04-23T09:49:25.973035Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# unfreeze_model function --- finetuning\ndef unfreeze_model(model, base_model, lr=1e-5):\n    # Unfreeze the base model\n    base_model.trainable = True\n    \n    # Freeze earlier layers, unfreeze later layers (fine-tuning)\n    for layer in base_model.layers[:-30]:  # Keep the first layers frozen\n        layer.trainable = False\n    \n    # Use simple float learning rate\n    model.compile(\n        optimizer=Adam(learning_rate=lr),  # Simple float learning rate\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy', \n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:25.975139Z","iopub.execute_input":"2025-04-23T09:49:25.975480Z","iopub.status.idle":"2025-04-23T09:49:25.993167Z","shell.execute_reply.started":"2025-04-23T09:49:25.975456Z","shell.execute_reply":"2025-04-23T09:49:25.992515Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Function to find the optimal threshold using the validation set\ndef find_optimal_threshold(model, val_ds):\n    # Get predictions\n    val_pred = model.predict(val_ds)\n    \n    # Get true labels\n    val_true = np.concatenate([y for x, y in val_ds], axis=0)\n    \n    # Calculate ROC curve and find optimal threshold\n    fpr, tpr, thresholds = roc_curve(val_true, val_pred)\n    j_scores = tpr - fpr\n    best_idx = np.argmax(j_scores)\n    best_threshold = thresholds[best_idx]\n    \n    print(f\"Optimal threshold: {best_threshold:.4f} (Youden's J = {j_scores[best_idx]:.4f})\")\n    print(f\"At threshold {best_threshold:.4f}: TPR={tpr[best_idx]:.4f}, FPR={fpr[best_idx]:.4f}\")\n    \n    return best_threshold\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:25.994587Z","iopub.execute_input":"2025-04-23T09:49:25.994804Z","iopub.status.idle":"2025-04-23T09:49:26.018581Z","shell.execute_reply.started":"2025-04-23T09:49:25.994787Z","shell.execute_reply":"2025-04-23T09:49:26.017864Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def evaluate_with_threshold(model, ds, threshold=0.5):\n    # Get predictions\n    pred = model.predict(ds)\n    \n    # Get true labels\n    true = np.concatenate([y for x, y in ds], axis=0)\n    \n    # Apply threshold\n    pred_binary = (pred > threshold).astype(int)\n    \n    # Calculate metrics\n    acc = accuracy_score(true, pred_binary)\n    auc = roc_auc_score(true, pred)\n    precision = precision_score(true, pred_binary)\n    recall = recall_score(true, pred_binary)\n    f1 = f1_score(true, pred_binary)\n    cm = confusion_matrix(true, pred_binary)\n    \n    # Calculate specificity\n    tn, fp, fn, tp = cm.ravel()\n    specificity = tn / (tn + fp)\n    \n    print(f\"Accuracy: {acc:.4f}\")\n    print(f\"AUC: {auc:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall (Sensitivity): {recall:.4f}\")\n    print(f\"Specificity: {specificity:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"Confusion Matrix:\\n{cm}\")\n    \n    return {\n        'accuracy': acc,\n        'auc': auc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'confusion_matrix': cm,\n        'predictions': pred,\n        'threshold': threshold\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:26.019415Z","iopub.execute_input":"2025-04-23T09:49:26.019687Z","iopub.status.idle":"2025-04-23T09:49:26.041906Z","shell.execute_reply.started":"2025-04-23T09:49:26.019665Z","shell.execute_reply":"2025-04-23T09:49:26.041285Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Prepare Callbacks\nos.makedirs(\"/kaggle/working/models\", exist_ok=True)\n\ndef get_callbacks(name):\n    return [\n        # Stop training when validation loss doesn't improve for 15 epochs\n        EarlyStopping(\n            monitor='val_loss',\n            patience=15,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Save the best model during training\n        ModelCheckpoint(\n            f\"/kaggle/working/models/{name}.keras\",\n            save_best_only=True,\n            monitor='val_auc',\n            mode='max',\n            verbose=1\n        ),\n        # Reduce learning rate when validation loss plateaus\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:26.042635Z","iopub.execute_input":"2025-04-23T09:49:26.042882Z","iopub.status.idle":"2025-04-23T09:49:26.062524Z","shell.execute_reply.started":"2025-04-23T09:49:26.042864Z","shell.execute_reply":"2025-04-23T09:49:26.061857Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"models_to_train = {\n    # \"VGG16\": VGG16\n    \"ResNet50\": ResNet50\n    # \"DenseNet121\": DenseNet121,\n    # \"EfficientNetB3\": EfficientNetB3  \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:27.153093Z","iopub.execute_input":"2025-04-23T09:49:27.153461Z","iopub.status.idle":"2025-04-23T09:49:27.157287Z","shell.execute_reply.started":"2025-04-23T09:49:27.153395Z","shell.execute_reply":"2025-04-23T09:49:27.156573Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Store training histories and model results\nhistory_dict = {}\nmodel_results = {}\nall_trained_models = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:28.801452Z","iopub.execute_input":"2025-04-23T09:49:28.801828Z","iopub.status.idle":"2025-04-23T09:49:28.806068Z","shell.execute_reply.started":"2025-04-23T09:49:28.801785Z","shell.execute_reply":"2025-04-23T09:49:28.805442Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"for name, model_fn in models_to_train.items():\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {name}...\")\n    print(f\"{'='*50}\")\n    \n    # Build model\n    model, base_model = build_improved_model(model_fn, name=name)\n    \n    print(f\"Initial training with frozen base layers...\")\n    # Phase 1: Train with frozen base model\n    history1 = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=10,  # Initial training epochs\n        class_weight=class_weight_dict,\n        callbacks=get_callbacks(f\"{name}_phase1\"),\n        verbose=2\n    )\n    \n    # Phase 2: Fine-tuning with unfrozen layers\n    print(f\"\\nFine-tuning with unfrozen layers...\")\n    model = unfreeze_model(model, base_model, lr=1e-5)\n    \n    history2 = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=10,  # Fine-tuning epochs\n        class_weight=class_weight_dict,\n        callbacks=get_callbacks(f\"{name}_phase2\"),\n        verbose=2\n    )\n    \n    # Find optimal threshold\n    print(\"\\nFinding optimal threshold...\")\n    optimal_threshold = find_optimal_threshold(model, val_ds)\n    \n    # Evaluate model on test set with optimal threshold\n    print(\"\\nEvaluating on test set...\")\n    test_results = evaluate_with_threshold(model, test_ds, threshold=optimal_threshold)\n    model_results[name] = test_results\n    \n    # Save model\n    model.save(f\"{name}_trained_model.h5\")\n    print(f\"Saved model: {name}_trained_model.h5\")\n    \n    # Save training history\n    combined_history = {\n        'phase1': history1.history,\n        'phase2': history2.history\n    }\n    history_dict[name] = combined_history\n    with open(f\"{name}_history.pkl\", \"wb\") as f:\n        pickle.dump(combined_history, f)\n    print(f\"Saved training history: {name}_history.pkl\")\n    \n    # Store model for ensemble\n    all_trained_models[name] = model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T09:49:30.233185Z","iopub.execute_input":"2025-04-23T09:49:30.233834Z","iopub.status.idle":"2025-04-23T10:02:53.758494Z","shell.execute_reply.started":"2025-04-23T09:49:30.233794Z","shell.execute_reply":"2025-04-23T10:02:53.757883Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nTraining ResNet50...\n==================================================\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nInitial training with frozen base layers...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1745401790.222419      95 service.cc:148] XLA service 0x79b748013c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1745401790.223330      95 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1745401792.018025      95 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1745401797.995799      95 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_auc improved from -inf to 0.65435, saving model to /kaggle/working/models/ResNet50_phase1.keras\n555/555 - 70s - 126ms/step - accuracy: 0.5805 - auc: 0.6082 - loss: 0.7748 - precision: 0.6297 - recall: 0.6018 - val_accuracy: 0.4987 - val_auc: 0.6543 - val_loss: 0.8510 - val_precision: 0.8242 - val_recall: 0.1287 - learning_rate: 1.0000e-04\nEpoch 2/10\n\nEpoch 2: val_auc improved from 0.65435 to 0.73045, saving model to /kaggle/working/models/ResNet50_phase1.keras\n555/555 - 30s - 54ms/step - accuracy: 0.6290 - auc: 0.6728 - loss: 0.6943 - precision: 0.6721 - recall: 0.6541 - val_accuracy: 0.5606 - val_auc: 0.7305 - val_loss: 1.2317 - val_precision: 0.5594 - val_recall: 0.9994 - learning_rate: 1.0000e-04\nEpoch 3/10\n\nEpoch 3: val_auc did not improve from 0.73045\n555/555 - 29s - 52ms/step - accuracy: 0.6515 - auc: 0.7028 - loss: 0.6596 - precision: 0.6911 - recall: 0.6786 - val_accuracy: 0.5830 - val_auc: 0.7242 - val_loss: 1.4458 - val_precision: 0.5729 - val_recall: 0.9914 - learning_rate: 1.0000e-04\nEpoch 4/10\n\nEpoch 4: val_auc did not improve from 0.73045\n555/555 - 29s - 52ms/step - accuracy: 0.6684 - auc: 0.7266 - loss: 0.6305 - precision: 0.7064 - recall: 0.6942 - val_accuracy: 0.6624 - val_auc: 0.7158 - val_loss: 0.6770 - val_precision: 0.6349 - val_recall: 0.9291 - learning_rate: 1.0000e-04\nEpoch 5/10\n\nEpoch 5: val_auc improved from 0.73045 to 0.81402, saving model to /kaggle/working/models/ResNet50_phase1.keras\n555/555 - 30s - 53ms/step - accuracy: 0.6834 - auc: 0.7438 - loss: 0.6125 - precision: 0.7179 - recall: 0.7126 - val_accuracy: 0.7064 - val_auc: 0.8140 - val_loss: 0.5642 - val_precision: 0.7966 - val_recall: 0.6362 - learning_rate: 1.0000e-04\nEpoch 6/10\n\nEpoch 6: val_auc did not improve from 0.81402\n555/555 - 29s - 51ms/step - accuracy: 0.6879 - auc: 0.7521 - loss: 0.6011 - precision: 0.7199 - recall: 0.7210 - val_accuracy: 0.6978 - val_auc: 0.8035 - val_loss: 0.6840 - val_precision: 0.6569 - val_recall: 0.9594 - learning_rate: 1.0000e-04\nEpoch 7/10\n\nEpoch 7: val_auc did not improve from 0.81402\n555/555 - 28s - 51ms/step - accuracy: 0.7002 - auc: 0.7702 - loss: 0.5799 - precision: 0.7344 - recall: 0.7247 - val_accuracy: 0.6723 - val_auc: 0.6838 - val_loss: 0.8249 - val_precision: 0.6376 - val_recall: 0.9554 - learning_rate: 1.0000e-04\nEpoch 8/10\n\nEpoch 8: val_auc did not improve from 0.81402\n555/555 - 29s - 52ms/step - accuracy: 0.7046 - auc: 0.7734 - loss: 0.5766 - precision: 0.7338 - recall: 0.7382 - val_accuracy: 0.5013 - val_auc: 0.7088 - val_loss: 1.3987 - val_precision: 0.9602 - val_recall: 0.1104 - learning_rate: 1.0000e-04\nEpoch 9/10\n\nEpoch 9: val_auc improved from 0.81402 to 0.82716, saving model to /kaggle/working/models/ResNet50_phase1.keras\n555/555 - 29s - 53ms/step - accuracy: 0.7127 - auc: 0.7843 - loss: 0.5633 - precision: 0.7451 - recall: 0.7372 - val_accuracy: 0.5954 - val_auc: 0.8272 - val_loss: 0.7205 - val_precision: 0.9348 - val_recall: 0.2952 - learning_rate: 1.0000e-04\nEpoch 10/10\n\nEpoch 10: val_auc did not improve from 0.82716\n\nEpoch 10: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n555/555 - 29s - 52ms/step - accuracy: 0.7147 - auc: 0.7897 - loss: 0.5547 - precision: 0.7467 - recall: 0.7393 - val_accuracy: 0.6449 - val_auc: 0.7164 - val_loss: 0.6497 - val_precision: 0.6641 - val_recall: 0.7351 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 5.\n\nFine-tuning with unfrozen layers...\nEpoch 1/10\n\nEpoch 1: val_auc improved from -inf to 0.82086, saving model to /kaggle/working/models/ResNet50_phase2.keras\n555/555 - 90s - 163ms/step - accuracy: 0.6401 - auc: 0.6941 - loss: 0.6774 - precision: 0.6840 - recall: 0.6597 - val_accuracy: 0.5909 - val_auc: 0.8209 - val_loss: 0.7801 - val_precision: 0.9299 - val_recall: 0.2883 - learning_rate: 1.0000e-05\nEpoch 2/10\n\nEpoch 2: val_auc improved from 0.82086 to 0.83919, saving model to /kaggle/working/models/ResNet50_phase2.keras\n555/555 - 41s - 73ms/step - accuracy: 0.6811 - auc: 0.7444 - loss: 0.6211 - precision: 0.7195 - recall: 0.7022 - val_accuracy: 0.6653 - val_auc: 0.8392 - val_loss: 0.5857 - val_precision: 0.8683 - val_recall: 0.4714 - learning_rate: 1.0000e-05\nEpoch 3/10\n\nEpoch 3: val_auc improved from 0.83919 to 0.86340, saving model to /kaggle/working/models/ResNet50_phase2.keras\n555/555 - 41s - 73ms/step - accuracy: 0.6982 - auc: 0.7668 - loss: 0.5914 - precision: 0.7336 - recall: 0.7207 - val_accuracy: 0.7597 - val_auc: 0.8634 - val_loss: 0.4721 - val_precision: 0.7992 - val_recall: 0.7603 - learning_rate: 1.0000e-05\nEpoch 4/10\n\nEpoch 4: val_auc did not improve from 0.86340\n555/555 - 38s - 69ms/step - accuracy: 0.7207 - auc: 0.7948 - loss: 0.5588 - precision: 0.7542 - recall: 0.7408 - val_accuracy: 0.6340 - val_auc: 0.7847 - val_loss: 0.7876 - val_precision: 0.8752 - val_recall: 0.4010 - learning_rate: 1.0000e-05\nEpoch 5/10\n\nEpoch 5: val_auc improved from 0.86340 to 0.88106, saving model to /kaggle/working/models/ResNet50_phase2.keras\n555/555 - 41s - 73ms/step - accuracy: 0.7302 - auc: 0.8106 - loss: 0.5368 - precision: 0.7614 - recall: 0.7521 - val_accuracy: 0.7179 - val_auc: 0.8811 - val_loss: 0.5384 - val_precision: 0.9068 - val_recall: 0.5509 - learning_rate: 1.0000e-05\nEpoch 6/10\n\nEpoch 6: val_auc did not improve from 0.88106\n555/555 - 39s - 69ms/step - accuracy: 0.7394 - auc: 0.8200 - loss: 0.5247 - precision: 0.7696 - recall: 0.7605 - val_accuracy: 0.7023 - val_auc: 0.8432 - val_loss: 0.5943 - val_precision: 0.8841 - val_recall: 0.5366 - learning_rate: 1.0000e-05\nEpoch 7/10\n\nEpoch 7: val_auc improved from 0.88106 to 0.88469, saving model to /kaggle/working/models/ResNet50_phase2.keras\n555/555 - 41s - 73ms/step - accuracy: 0.7408 - auc: 0.8238 - loss: 0.5181 - precision: 0.7747 - recall: 0.7550 - val_accuracy: 0.8165 - val_auc: 0.8847 - val_loss: 0.4344 - val_precision: 0.7919 - val_recall: 0.9102 - learning_rate: 1.0000e-05\nEpoch 8/10\n\nEpoch 8: val_auc did not improve from 0.88469\n555/555 - 39s - 70ms/step - accuracy: 0.7477 - auc: 0.8321 - loss: 0.5059 - precision: 0.7800 - recall: 0.7630 - val_accuracy: 0.7524 - val_auc: 0.8812 - val_loss: 0.4535 - val_precision: 0.8370 - val_recall: 0.6905 - learning_rate: 1.0000e-05\nEpoch 9/10\n\nEpoch 9: val_auc did not improve from 0.88469\n555/555 - 39s - 70ms/step - accuracy: 0.7535 - auc: 0.8422 - loss: 0.4889 - precision: 0.7832 - recall: 0.7717 - val_accuracy: 0.7384 - val_auc: 0.8575 - val_loss: 0.4856 - val_precision: 0.8489 - val_recall: 0.6459 - learning_rate: 1.0000e-05\nEpoch 10/10\n\nEpoch 10: val_auc did not improve from 0.88469\n555/555 - 39s - 70ms/step - accuracy: 0.7542 - auc: 0.8401 - loss: 0.4929 - precision: 0.7854 - recall: 0.7695 - val_accuracy: 0.7610 - val_auc: 0.8784 - val_loss: 0.4344 - val_precision: 0.8132 - val_recall: 0.7420 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 7.\n\nFinding optimal threshold...\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 91ms/step\nOptimal threshold: 0.6041 (Youden's J = 0.6193)\nAt threshold 0.6041: TPR=0.8913, FPR=0.2720\n\nEvaluating on test set...\n\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step\nAccuracy: 0.8267\nAUC: 0.8825\nPrecision: 0.8160\nRecall (Sensitivity): 0.8901\nSpecificity: 0.7466\nF1 Score: 0.8514\nConfusion Matrix:\n[[1217  413]\n [ 226 1831]]\nSaved model: ResNet50_trained_model.h5\nSaved training history: ResNet50_history.pkl\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}