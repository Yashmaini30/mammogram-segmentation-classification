{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11420152,"sourceType":"datasetVersion","datasetId":7152221},{"sourceId":351323,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":293228,"modelId":313863}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, ResNet50, DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.utils.class_weight import compute_class_weight\nimport pickle\nimport collections\nfrom sklearn.metrics import (\n    accuracy_score, roc_auc_score, precision_score, recall_score,\n    f1_score, confusion_matrix, roc_curve\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use Mixed Precision (save VRAM)\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\nprint(\"mixed precision enabled.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Preprocessed Data --- balanced checked\nDATA_PATH = \"/kaggle/input/preprocessed-mammo-splits\"  \ntrain = np.load(os.path.join(DATA_PATH, \"train_data.npz\"))\nval = np.load(os.path.join(DATA_PATH, \"val_data.npz\"))\ntest = np.load(os.path.join(DATA_PATH, \"test_data.npz\"))\n\nX_train, y_train = train[\"X\"], train[\"y\"]\nX_val, y_val = val[\"X\"], val[\"y\"]\nX_test, y_test = test[\"X\"], test[\"y\"]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalize\nX_train, X_val, X_test = X_train / 255.0, X_val / 255.0, X_test / 255.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute Class Weights\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(zip(np.unique(y_train), class_weights))\nprint(\"Class Weights:\", class_weight_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_rgb(image, label):\n    image_rgb = tf.image.grayscale_to_rgb(image)  \n    image_rgb = tf.squeeze(image_rgb) \n    return image_rgb, label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Expand dims because TF expects (H, W, 1) from (H, W)\nX_train = X_train[..., np.newaxis].astype(\"float32\")\nX_val = X_val[..., np.newaxis].astype(\"float32\")\nX_test = X_test[..., np.newaxis].astype(\"float32\")\n\n# Create datasets\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\ntest_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\n# Shuffle, batch, convert to RGB, prefetch\ntrain_ds = (\n    train_ds.shuffle(1024)\n    .map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\nval_ds = (\n    val_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\ntest_ds = (\n    test_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_model(base_model_fn, name=\"model\"):\n    base_model = base_model_fn(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n    base_model.trainable = False  \n\n    inputs = Input(shape=(224, 224, 3))\n    x = base_model(inputs, training=False)  \n    x = GlobalAveragePooling2D()(x) \n    x = Dropout(0.3)(x)  \n    x = Dense(128, activation='relu')(x)  \n    outputs = Dense(1, activation='sigmoid', dtype='float32')(x)  \n\n    model = Model(inputs, outputs, name=name)\n    model.compile(optimizer=Adam(learning_rate=1e-4),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]) \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T07:34:13.830920Z","iopub.execute_input":"2025-04-22T07:34:13.831562Z","iopub.status.idle":"2025-04-22T07:34:13.836491Z","shell.execute_reply.started":"2025-04-22T07:34:13.831538Z","shell.execute_reply":"2025-04-22T07:34:13.835729Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Prepare Callbacks\nos.makedirs(\"/kaggle/working/models\", exist_ok=True)\ncallbacks = lambda name: [\n    EarlyStopping(patience=50, restore_best_weights=True),\n    ModelCheckpoint(f\"/kaggle/working/models/{name}.keras\", save_best_only=True)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T07:34:17.499409Z","iopub.execute_input":"2025-04-22T07:34:17.500176Z","iopub.status.idle":"2025-04-22T07:34:17.504251Z","shell.execute_reply.started":"2025-04-22T07:34:17.500151Z","shell.execute_reply":"2025-04-22T07:34:17.503494Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Train and Save Models\nmodels = {\n    \"VGG16\": VGG16,\n    \"ResNet50\": ResNet50,\n    \"DenseNet121\": DenseNet121\n}\n\nhistory_dict = {}\n\nfor name, fn in models.items():\n    print(f\"\\nTraining {name}...\")\n    \n    # Build model\n    model = build_model(fn, name=name)\n    \n    # Train model\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=100,\n        batch_size=32,\n        class_weight=class_weight_dict,\n        callbacks=callbacks(name),\n        verbose=2\n    )\n\n    # Save model\n    model.save(f\"{name}_trained_model.h5\")\n    print(f\"Saved model: {name}_trained_model.h5\")\n\n    # Save training history\n    history_dict[name] = history.history\n    with open(f\"{name}_history.pkl\", \"wb\") as f:\n        pickle.dump(history.history, f)\n    print(f\"Saved training history: {name}_history.pkl\")\n\nprint(\"\\n Training completed and all models & histories saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T07:35:59.514605Z","iopub.execute_input":"2025-04-22T07:35:59.514906Z"}},"outputs":[{"name":"stdout","text":"\nTraining VGG16...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1745307366.998941      90 service.cc:148] XLA service 0x77febc00e190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1745307366.999512      90 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1745307367.500090      90 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1745307377.547918      90 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"555/555 - 79s - 142ms/step - accuracy: 0.5013 - auc: 0.5043 - loss: 0.6957 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6885\nEpoch 2/100\n555/555 - 46s - 83ms/step - accuracy: 0.5000 - auc: 0.5003 - loss: 0.6950 - val_accuracy: 0.5578 - val_auc: 0.5004 - val_loss: 0.6869\nEpoch 3/100\n555/555 - 46s - 82ms/step - accuracy: 0.4980 - auc: 0.4995 - loss: 0.6950 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6872\nEpoch 4/100\n555/555 - 46s - 82ms/step - accuracy: 0.4997 - auc: 0.4965 - loss: 0.6951 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6872\nEpoch 5/100\n555/555 - 46s - 83ms/step - accuracy: 0.4973 - auc: 0.5022 - loss: 0.6944 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6865\nEpoch 6/100\n555/555 - 46s - 83ms/step - accuracy: 0.5028 - auc: 0.5032 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6866\nEpoch 7/100\n555/555 - 46s - 82ms/step - accuracy: 0.5033 - auc: 0.4980 - loss: 0.6949 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6906\nEpoch 8/100\n555/555 - 46s - 83ms/step - accuracy: 0.4983 - auc: 0.4993 - loss: 0.6942 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6900\nEpoch 9/100\n555/555 - 46s - 83ms/step - accuracy: 0.5052 - auc: 0.5082 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6873\nEpoch 10/100\n555/555 - 46s - 83ms/step - accuracy: 0.5016 - auc: 0.5016 - loss: 0.6944 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6888\nEpoch 11/100\n555/555 - 46s - 82ms/step - accuracy: 0.4979 - auc: 0.5009 - loss: 0.6942 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6867\nEpoch 12/100\n555/555 - 46s - 82ms/step - accuracy: 0.5059 - auc: 0.5029 - loss: 0.6943 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6874\nEpoch 13/100\n555/555 - 46s - 82ms/step - accuracy: 0.5020 - auc: 0.5032 - loss: 0.6943 - val_accuracy: 0.5578 - val_auc: 0.5123 - val_loss: 0.6867\nEpoch 14/100\n555/555 - 46s - 82ms/step - accuracy: 0.5000 - auc: 0.4974 - loss: 0.6945 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6894\nEpoch 15/100\n555/555 - 46s - 82ms/step - accuracy: 0.4989 - auc: 0.4987 - loss: 0.6943 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6865\nEpoch 16/100\n555/555 - 46s - 83ms/step - accuracy: 0.5023 - auc: 0.5023 - loss: 0.6944 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6871\nEpoch 17/100\n555/555 - 46s - 82ms/step - accuracy: 0.4966 - auc: 0.5011 - loss: 0.6942 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6872\nEpoch 18/100\n555/555 - 46s - 83ms/step - accuracy: 0.5040 - auc: 0.5054 - loss: 0.6943 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6865\nEpoch 19/100\n555/555 - 46s - 83ms/step - accuracy: 0.5085 - auc: 0.5043 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6878\nEpoch 20/100\n555/555 - 46s - 82ms/step - accuracy: 0.4996 - auc: 0.5022 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5259 - val_loss: 0.6865\nEpoch 21/100\n555/555 - 46s - 82ms/step - accuracy: 0.5022 - auc: 0.5037 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6869\nEpoch 22/100\n555/555 - 46s - 83ms/step - accuracy: 0.4984 - auc: 0.4967 - loss: 0.6944 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6893\nEpoch 23/100\n555/555 - 46s - 83ms/step - accuracy: 0.5004 - auc: 0.5043 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6876\nEpoch 24/100\n555/555 - 46s - 83ms/step - accuracy: 0.5017 - auc: 0.5026 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6886\nEpoch 25/100\n555/555 - 46s - 83ms/step - accuracy: 0.4961 - auc: 0.5027 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6885\nEpoch 26/100\n555/555 - 46s - 83ms/step - accuracy: 0.5010 - auc: 0.5020 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5004 - val_loss: 0.6869\nEpoch 27/100\n555/555 - 46s - 83ms/step - accuracy: 0.5060 - auc: 0.5061 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6867\nEpoch 28/100\n555/555 - 46s - 83ms/step - accuracy: 0.5039 - auc: 0.5034 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.4999 - val_loss: 0.6865\nEpoch 29/100\n555/555 - 46s - 83ms/step - accuracy: 0.4988 - auc: 0.5005 - loss: 0.6944 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6879\nEpoch 30/100\n555/555 - 46s - 83ms/step - accuracy: 0.4968 - auc: 0.4978 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 31/100\n555/555 - 46s - 83ms/step - accuracy: 0.5005 - auc: 0.5026 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6870\nEpoch 32/100\n555/555 - 46s - 83ms/step - accuracy: 0.4990 - auc: 0.4964 - loss: 0.6945 - val_accuracy: 0.5578 - val_auc: 0.5539 - val_loss: 0.6897\nEpoch 33/100\n555/555 - 46s - 83ms/step - accuracy: 0.4966 - auc: 0.4975 - loss: 0.6942 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6888\nEpoch 34/100\n555/555 - 46s - 83ms/step - accuracy: 0.5022 - auc: 0.5024 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6882\nEpoch 35/100\n555/555 - 46s - 83ms/step - accuracy: 0.5046 - auc: 0.5057 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6894\nEpoch 36/100\n555/555 - 46s - 83ms/step - accuracy: 0.4911 - auc: 0.4957 - loss: 0.6944 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6878\nEpoch 37/100\n555/555 - 46s - 83ms/step - accuracy: 0.5119 - auc: 0.5158 - loss: 0.6930 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6880\nEpoch 38/100\n555/555 - 46s - 83ms/step - accuracy: 0.5046 - auc: 0.5012 - loss: 0.6941 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6941\nEpoch 39/100\n555/555 - 46s - 83ms/step - accuracy: 0.5047 - auc: 0.5079 - loss: 0.6936 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6900\nEpoch 40/100\n555/555 - 46s - 83ms/step - accuracy: 0.5056 - auc: 0.5062 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6873\nEpoch 41/100\n555/555 - 46s - 83ms/step - accuracy: 0.4999 - auc: 0.5011 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6881\nEpoch 42/100\n555/555 - 46s - 83ms/step - accuracy: 0.5031 - auc: 0.5032 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6885\nEpoch 43/100\n555/555 - 46s - 83ms/step - accuracy: 0.5090 - auc: 0.5084 - loss: 0.6936 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6880\nEpoch 44/100\n555/555 - 46s - 83ms/step - accuracy: 0.5089 - auc: 0.5103 - loss: 0.6934 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6873\nEpoch 45/100\n555/555 - 46s - 83ms/step - accuracy: 0.5055 - auc: 0.5001 - loss: 0.6942 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6867\nEpoch 46/100\n555/555 - 46s - 83ms/step - accuracy: 0.4971 - auc: 0.5021 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6880\nEpoch 47/100\n555/555 - 46s - 83ms/step - accuracy: 0.5051 - auc: 0.5067 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6871\nEpoch 48/100\n555/555 - 46s - 82ms/step - accuracy: 0.5031 - auc: 0.5033 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6892\nEpoch 49/100\n555/555 - 46s - 83ms/step - accuracy: 0.4979 - auc: 0.5014 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6864\nEpoch 50/100\n555/555 - 46s - 82ms/step - accuracy: 0.5053 - auc: 0.5023 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6874\nEpoch 51/100\n555/555 - 46s - 82ms/step - accuracy: 0.5033 - auc: 0.5021 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6874\nEpoch 52/100\n555/555 - 46s - 82ms/step - accuracy: 0.5056 - auc: 0.5025 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 53/100\n555/555 - 46s - 82ms/step - accuracy: 0.4977 - auc: 0.4989 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 54/100\n555/555 - 46s - 82ms/step - accuracy: 0.5010 - auc: 0.5039 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 55/100\n555/555 - 46s - 82ms/step - accuracy: 0.4972 - auc: 0.4968 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6893\nEpoch 56/100\n555/555 - 46s - 82ms/step - accuracy: 0.5074 - auc: 0.5068 - loss: 0.6935 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6886\nEpoch 57/100\n555/555 - 46s - 83ms/step - accuracy: 0.4947 - auc: 0.4995 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6866\nEpoch 58/100\n555/555 - 46s - 83ms/step - accuracy: 0.4967 - auc: 0.5008 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5012 - val_loss: 0.6873\nEpoch 59/100\n555/555 - 46s - 83ms/step - accuracy: 0.5006 - auc: 0.5046 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6875\nEpoch 60/100\n555/555 - 46s - 83ms/step - accuracy: 0.4994 - auc: 0.4978 - loss: 0.6942 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6867\nEpoch 61/100\n555/555 - 46s - 83ms/step - accuracy: 0.4974 - auc: 0.5046 - loss: 0.6935 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6885\nEpoch 62/100\n555/555 - 46s - 83ms/step - accuracy: 0.5079 - auc: 0.4991 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6904\nEpoch 63/100\n555/555 - 46s - 83ms/step - accuracy: 0.4992 - auc: 0.5031 - loss: 0.6936 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6879\nEpoch 64/100\n555/555 - 46s - 83ms/step - accuracy: 0.5073 - auc: 0.5061 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6888\nEpoch 65/100\n555/555 - 46s - 83ms/step - accuracy: 0.4995 - auc: 0.5005 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6873\nEpoch 66/100\n555/555 - 46s - 83ms/step - accuracy: 0.5001 - auc: 0.5015 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6874\nEpoch 67/100\n555/555 - 46s - 83ms/step - accuracy: 0.4965 - auc: 0.5004 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6873\nEpoch 68/100\n555/555 - 46s - 83ms/step - accuracy: 0.5014 - auc: 0.5089 - loss: 0.6934 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6870\nEpoch 69/100\n555/555 - 46s - 83ms/step - accuracy: 0.5000 - auc: 0.5003 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6865\nEpoch 70/100\n555/555 - 46s - 83ms/step - accuracy: 0.4952 - auc: 0.4998 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6864\nEpoch 71/100\n555/555 - 46s - 83ms/step - accuracy: 0.4961 - auc: 0.4981 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6866\nEpoch 72/100\n555/555 - 46s - 83ms/step - accuracy: 0.5068 - auc: 0.5115 - loss: 0.6933 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6866\nEpoch 73/100\n555/555 - 46s - 83ms/step - accuracy: 0.5023 - auc: 0.5009 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6871\nEpoch 74/100\n555/555 - 46s - 83ms/step - accuracy: 0.5010 - auc: 0.4942 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6880\nEpoch 75/100\n555/555 - 46s - 83ms/step - accuracy: 0.4968 - auc: 0.4976 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6875\nEpoch 76/100\n555/555 - 46s - 83ms/step - accuracy: 0.4963 - auc: 0.5003 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.4997 - val_loss: 0.6872\nEpoch 77/100\n555/555 - 46s - 83ms/step - accuracy: 0.4938 - auc: 0.5058 - loss: 0.6934 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6866\nEpoch 78/100\n555/555 - 46s - 83ms/step - accuracy: 0.4961 - auc: 0.5003 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6871\nEpoch 79/100\n555/555 - 46s - 83ms/step - accuracy: 0.4955 - auc: 0.4954 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6881\nEpoch 80/100\n555/555 - 46s - 83ms/step - accuracy: 0.4995 - auc: 0.5060 - loss: 0.6935 - val_accuracy: 0.5578 - val_auc: 0.5001 - val_loss: 0.6873\nEpoch 81/100\n555/555 - 46s - 83ms/step - accuracy: 0.5027 - auc: 0.5046 - loss: 0.6935 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6867\nEpoch 82/100\n555/555 - 46s - 83ms/step - accuracy: 0.4981 - auc: 0.5030 - loss: 0.6936 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6871\nEpoch 83/100\n555/555 - 46s - 83ms/step - accuracy: 0.5001 - auc: 0.5004 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6886\nEpoch 84/100\n555/555 - 46s - 83ms/step - accuracy: 0.4997 - auc: 0.5014 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6899\nEpoch 85/100\n555/555 - 46s - 83ms/step - accuracy: 0.5076 - auc: 0.5113 - loss: 0.6933 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6872\nEpoch 86/100\n555/555 - 46s - 83ms/step - accuracy: 0.5105 - auc: 0.5058 - loss: 0.6935 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6871\nEpoch 87/100\n555/555 - 46s - 83ms/step - accuracy: 0.4862 - auc: 0.4960 - loss: 0.6941 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6864\nEpoch 88/100\n555/555 - 46s - 83ms/step - accuracy: 0.5098 - auc: 0.5082 - loss: 0.6935 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6869\nEpoch 89/100\n555/555 - 46s - 83ms/step - accuracy: 0.4960 - auc: 0.4994 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6885\nEpoch 90/100\n555/555 - 46s - 83ms/step - accuracy: 0.4964 - auc: 0.4980 - loss: 0.6939 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6876\nEpoch 91/100\n555/555 - 46s - 83ms/step - accuracy: 0.4945 - auc: 0.4964 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6899\nEpoch 92/100\n555/555 - 46s - 83ms/step - accuracy: 0.5012 - auc: 0.5074 - loss: 0.6934 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6874\nEpoch 93/100\n555/555 - 46s - 83ms/step - accuracy: 0.5023 - auc: 0.4965 - loss: 0.6940 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6893\nEpoch 94/100\n555/555 - 46s - 83ms/step - accuracy: 0.5019 - auc: 0.5014 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5125 - val_loss: 0.6883\nEpoch 95/100\n555/555 - 46s - 83ms/step - accuracy: 0.4926 - auc: 0.5008 - loss: 0.6935 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6871\nEpoch 96/100\n555/555 - 46s - 83ms/step - accuracy: 0.4923 - auc: 0.5002 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5111 - val_loss: 0.6877\nEpoch 97/100\n555/555 - 46s - 83ms/step - accuracy: 0.4975 - auc: 0.5024 - loss: 0.6937 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 98/100\n555/555 - 46s - 83ms/step - accuracy: 0.5021 - auc: 0.4996 - loss: 0.6938 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6892\nEpoch 99/100\n555/555 - 46s - 83ms/step - accuracy: 0.4991 - auc: 0.5028 - loss: 0.6936 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6886\nEpoch 100/100\n555/555 - 46s - 83ms/step - accuracy: 0.5026 - auc: 0.5025 - loss: 0.6936 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6898\nSaved model: VGG16_trained_model.h5\nSaved training history: VGG16_history.pkl\n\nTraining ResNet50...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/100\n555/555 - 61s - 111ms/step - accuracy: 0.5057 - auc: 0.5029 - loss: 0.7041 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6895\nEpoch 2/100\n555/555 - 27s - 49ms/step - accuracy: 0.4939 - auc: 0.4975 - loss: 0.6990 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6910\nEpoch 3/100\n555/555 - 28s - 51ms/step - accuracy: 0.5083 - auc: 0.5096 - loss: 0.6974 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6887\nEpoch 4/100\n555/555 - 27s - 49ms/step - accuracy: 0.5045 - auc: 0.5040 - loss: 0.6970 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6934\nEpoch 5/100\n555/555 - 27s - 49ms/step - accuracy: 0.5017 - auc: 0.5018 - loss: 0.6978 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6916\nEpoch 6/100\n555/555 - 28s - 51ms/step - accuracy: 0.5039 - auc: 0.5003 - loss: 0.6979 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 7/100\n555/555 - 28s - 51ms/step - accuracy: 0.4987 - auc: 0.5001 - loss: 0.6981 - val_accuracy: 0.5578 - val_auc: 0.5054 - val_loss: 0.6867\nEpoch 8/100\n555/555 - 27s - 49ms/step - accuracy: 0.4997 - auc: 0.4939 - loss: 0.6983 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6984\nEpoch 9/100\n555/555 - 27s - 49ms/step - accuracy: 0.4930 - auc: 0.4912 - loss: 0.6975 - val_accuracy: 0.4426 - val_auc: 0.5000 - val_loss: 0.6932\nEpoch 10/100\n555/555 - 27s - 49ms/step - accuracy: 0.4947 - auc: 0.4965 - loss: 0.6964 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6961\nEpoch 11/100\n555/555 - 27s - 50ms/step - accuracy: 0.4930 - auc: 0.4900 - loss: 0.6978 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6875\nEpoch 12/100\n555/555 - 28s - 51ms/step - accuracy: 0.5026 - auc: 0.5034 - loss: 0.6965 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6865\nEpoch 13/100\n555/555 - 28s - 50ms/step - accuracy: 0.4996 - auc: 0.5030 - loss: 0.6965 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6878\nEpoch 14/100\n555/555 - 28s - 50ms/step - accuracy: 0.5041 - auc: 0.5040 - loss: 0.6965 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6884\nEpoch 15/100\n555/555 - 28s - 50ms/step - accuracy: 0.4970 - auc: 0.4973 - loss: 0.6972 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.7051\nEpoch 16/100\n555/555 - 27s - 50ms/step - accuracy: 0.5048 - auc: 0.5024 - loss: 0.6963 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6898\nEpoch 17/100\n555/555 - 27s - 50ms/step - accuracy: 0.4899 - auc: 0.4917 - loss: 0.6961 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6865\nEpoch 18/100\n555/555 - 27s - 50ms/step - accuracy: 0.5059 - auc: 0.5072 - loss: 0.6960 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.7026\nEpoch 19/100\n555/555 - 27s - 49ms/step - accuracy: 0.5024 - auc: 0.5027 - loss: 0.6963 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6904\nEpoch 20/100\n555/555 - 27s - 49ms/step - accuracy: 0.4976 - auc: 0.5000 - loss: 0.6963 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 21/100\n555/555 - 27s - 49ms/step - accuracy: 0.5009 - auc: 0.5046 - loss: 0.6963 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6874\nEpoch 22/100\n555/555 - 27s - 49ms/step - accuracy: 0.5001 - auc: 0.5013 - loss: 0.6956 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6894\nEpoch 23/100\n555/555 - 27s - 49ms/step - accuracy: 0.4932 - auc: 0.4980 - loss: 0.6965 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 24/100\n555/555 - 27s - 49ms/step - accuracy: 0.4944 - auc: 0.4978 - loss: 0.6966 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6866\nEpoch 25/100\n555/555 - 27s - 49ms/step - accuracy: 0.5048 - auc: 0.5039 - loss: 0.6959 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6928\nEpoch 26/100\n555/555 - 27s - 49ms/step - accuracy: 0.5081 - auc: 0.5069 - loss: 0.6954 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6933\nEpoch 27/100\n555/555 - 29s - 52ms/step - accuracy: 0.5005 - auc: 0.5015 - loss: 0.6956 - val_accuracy: 0.5578 - val_auc: 0.5452 - val_loss: 0.6865\nEpoch 28/100\n555/555 - 28s - 51ms/step - accuracy: 0.4989 - auc: 0.4953 - loss: 0.6963 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6864\nEpoch 29/100\n555/555 - 27s - 49ms/step - accuracy: 0.5005 - auc: 0.5040 - loss: 0.6955 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6870\nEpoch 30/100\n555/555 - 27s - 49ms/step - accuracy: 0.5068 - auc: 0.5046 - loss: 0.6967 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6952\nEpoch 31/100\n555/555 - 27s - 49ms/step - accuracy: 0.4994 - auc: 0.5014 - loss: 0.6957 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6868\nEpoch 32/100\n555/555 - 27s - 49ms/step - accuracy: 0.5083 - auc: 0.5045 - loss: 0.6956 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6918\nEpoch 33/100\n555/555 - 27s - 49ms/step - accuracy: 0.4992 - auc: 0.4981 - loss: 0.6957 - val_accuracy: 0.5578 - val_auc: 0.5008 - val_loss: 0.6865\nEpoch 34/100\n555/555 - 27s - 50ms/step - accuracy: 0.4991 - auc: 0.5023 - loss: 0.6954 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6875\nEpoch 35/100\n555/555 - 27s - 49ms/step - accuracy: 0.5074 - auc: 0.5056 - loss: 0.6949 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6935\nEpoch 36/100\n555/555 - 27s - 50ms/step - accuracy: 0.4978 - auc: 0.4974 - loss: 0.6958 - val_accuracy: 0.4422 - val_auc: 0.5000 - val_loss: 0.6934\nEpoch 37/100\n555/555 - 28s - 51ms/step - accuracy: 0.5039 - auc: 0.5054 - loss: 0.6952 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6864\nEpoch 38/100\n555/555 - 27s - 49ms/step - accuracy: 0.4992 - auc: 0.4977 - loss: 0.6962 - val_accuracy: 0.5578 - val_auc: 0.5004 - val_loss: 0.6890\nEpoch 39/100\n555/555 - 27s - 49ms/step - accuracy: 0.5010 - auc: 0.5000 - loss: 0.6957 - val_accuracy: 0.5578 - val_auc: 0.5000 - val_loss: 0.6923\nEpoch 40/100\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}