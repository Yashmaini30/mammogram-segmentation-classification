{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, EfficientNetB3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import KFold\nimport pickle\nimport time\nimport collections\nfrom sklearn.metrics import (\n    accuracy_score, roc_auc_score, precision_score, recall_score,\n    f1_score, confusion_matrix, roc_curve\n)\nfrom skopt import gp_minimize\nfrom skopt.space import Real, Integer, Categorical\nfrom skopt.utils import use_named_args","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:09:27.508693Z","iopub.execute_input":"2025-04-26T08:09:27.508853Z","iopub.status.idle":"2025-04-26T08:09:41.308017Z","shell.execute_reply.started":"2025-04-26T08:09:27.508838Z","shell.execute_reply":"2025-04-26T08:09:41.307412Z"}},"outputs":[{"name":"stderr","text":"2025-04-26 08:09:28.871944: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745654969.056902      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745654969.108281      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Use Mixed Precision (save VRAM)\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\nprint(\"mixed precision enabled.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:09:41.308762Z","iopub.execute_input":"2025-04-26T08:09:41.309197Z","iopub.status.idle":"2025-04-26T08:09:41.313483Z","shell.execute_reply.started":"2025-04-26T08:09:41.309161Z","shell.execute_reply":"2025-04-26T08:09:41.312756Z"}},"outputs":[{"name":"stdout","text":"mixed precision enabled.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Load Preprocessed Data --- balanced checked\nDATA_PATH = \"/kaggle/input/preprocessed-mammo-splits\"  \ntrain = np.load(os.path.join(DATA_PATH, \"train_data.npz\"))\nval = np.load(os.path.join(DATA_PATH, \"val_data.npz\"))\ntest = np.load(os.path.join(DATA_PATH, \"test_data.npz\"))\n\nX_train, y_train = train[\"X\"], train[\"y\"]\nX_val, y_val = val[\"X\"], val[\"y\"]\nX_test, y_test = test[\"X\"], test[\"y\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:09:41.315616Z","iopub.execute_input":"2025-04-26T08:09:41.315876Z","iopub.status.idle":"2025-04-26T08:10:12.452135Z","shell.execute_reply.started":"2025-04-26T08:09:41.315858Z","shell.execute_reply":"2025-04-26T08:10:12.451575Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Compute Class Weights\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(zip(np.unique(y_train), class_weights))\nprint(\"Class Weights:\", class_weight_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:12.452796Z","iopub.execute_input":"2025-04-26T08:10:12.452981Z","iopub.status.idle":"2025-04-26T08:10:12.462398Z","shell.execute_reply.started":"2025-04-26T08:10:12.452964Z","shell.execute_reply":"2025-04-26T08:10:12.461859Z"}},"outputs":[{"name":"stdout","text":"Class Weights: {0: 1.1308917197452228, 1: 0.8962645128722867}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Expand dims because TF expects (H, W, 1) from (H, W)\nX_train = X_train[..., np.newaxis].astype(\"float32\")\nX_val = X_val[..., np.newaxis].astype(\"float32\")\nX_test = X_test[..., np.newaxis].astype(\"float32\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:12.463146Z","iopub.execute_input":"2025-04-26T08:10:12.463366Z","iopub.status.idle":"2025-04-26T08:10:14.447076Z","shell.execute_reply.started":"2025-04-26T08:10:12.463341Z","shell.execute_reply":"2025-04-26T08:10:14.446512Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Enhanced data augmentation\ndef convert_to_rgb(image, label):\n    image_rgb = tf.image.grayscale_to_rgb(image)  \n    image_rgb = tf.squeeze(image_rgb) \n    return image_rgb, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:14.447853Z","iopub.execute_input":"2025-04-26T08:10:14.448053Z","iopub.status.idle":"2025-04-26T08:10:14.451936Z","shell.execute_reply.started":"2025-04-26T08:10:14.448038Z","shell.execute_reply":"2025-04-26T08:10:14.451278Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def augment(image, label):\n    # Random rotation (0-15 degrees)\n    angle = tf.random.uniform([], -0.26, 0.26)  # ~15 degrees in radians\n    image = tf.image.rot90(image, k=tf.cast(angle * 2 / 3.14159, tf.int32))\n    \n    # Random flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    # Random brightness/contrast adjustments\n    image = tf.image.random_brightness(image, 0.2)\n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    \n    # Random zoom (crop and resize)\n    zoom_factor = tf.random.uniform([], 0.8, 1.0, dtype=tf.float32)\n    h, w = tf.shape(image)[0], tf.shape(image)[1]\n    crop_size_h = tf.cast(tf.cast(h, tf.float32) * zoom_factor, tf.int32)\n    crop_size_w = tf.cast(tf.cast(w, tf.float32) * zoom_factor, tf.int32)\n    \n    # Ensure crop dimensions don't exceed image dimensions\n    crop_size_h = tf.minimum(crop_size_h, h)\n    crop_size_w = tf.minimum(crop_size_w, w)\n    \n    image = tf.image.random_crop(image, size=[crop_size_h, crop_size_w, 3])\n    image = tf.image.resize(image, [224, 224])\n    \n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:14.452749Z","iopub.execute_input":"2025-04-26T08:10:14.453065Z","iopub.status.idle":"2025-04-26T08:10:14.485660Z","shell.execute_reply.started":"2025-04-26T08:10:14.453037Z","shell.execute_reply":"2025-04-26T08:10:14.484850Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"BATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Create datasets\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\ntest_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\n# Apply preprocessing and augmentation\ntrain_ds = (\n    train_ds.shuffle(1024)\n    .map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .map(augment, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\nval_ds = (\n    val_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\ntest_ds = (\n    test_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:14.486567Z","iopub.execute_input":"2025-04-26T08:10:14.486821Z","iopub.status.idle":"2025-04-26T08:10:27.830590Z","shell.execute_reply.started":"2025-04-26T08:10:14.486794Z","shell.execute_reply":"2025-04-26T08:10:27.830060Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745655016.584264      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Bayesian Optimization Space\nbayes_space = [\n    Real(1e-5, 1e-3, \"log-uniform\", name=\"learning_rate\"),\n    Integer(128, 1024, name=\"dense_units_1\"),\n    Integer(64, 512, name=\"dense_units_2\"),\n    Real(0.2, 0.7, name=\"dropout_rate_1\"),\n    Real(0.1, 0.5, name=\"dropout_rate_2\"),\n    Integer(10, 50, name=\"unfreeze_layers\")\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:27.834591Z","iopub.execute_input":"2025-04-26T08:10:27.834878Z","iopub.status.idle":"2025-04-26T08:10:27.844017Z","shell.execute_reply.started":"2025-04-26T08:10:27.834851Z","shell.execute_reply":"2025-04-26T08:10:27.843265Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def build_tuned_model(base_model_fn, hyperparams, name=\"model\"):\n    base_model = base_model_fn(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n    base_model.trainable = False\n    \n    inputs = Input(shape=(224, 224, 3))\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    \n    x = Dense(hyperparams[\"dense_units_1\"], activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(hyperparams[\"dropout_rate_1\"])(x)\n    \n    x = Dense(hyperparams[\"dense_units_2\"], activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(hyperparams[\"dropout_rate_2\"])(x)\n    \n    outputs = Dense(1, activation='sigmoid', dtype='float32')(x)\n    \n    model = Model(inputs, outputs, name=name)\n\n    model.compile(\n        optimizer=Adam(learning_rate=hyperparams[\"learning_rate\"]),\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy', \n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    \n    return model, base_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:27.844893Z","iopub.execute_input":"2025-04-26T08:10:27.845136Z","iopub.status.idle":"2025-04-26T08:10:27.860285Z","shell.execute_reply.started":"2025-04-26T08:10:27.845114Z","shell.execute_reply":"2025-04-26T08:10:27.859686Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def unfreeze_tuned_model(model, base_model, hyperparams):\n    base_model.trainable = True\n    \n    for layer in base_model.layers[:-hyperparams[\"unfreeze_layers\"]]:\n        layer.trainable = False\n    \n    model.compile(\n        optimizer=Adam(learning_rate=hyperparams[\"learning_rate\"]/10),\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy', \n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:10:45.543657Z","iopub.execute_input":"2025-04-26T08:10:45.544243Z","iopub.status.idle":"2025-04-26T08:10:45.549167Z","shell.execute_reply.started":"2025-04-26T08:10:45.544225Z","shell.execute_reply":"2025-04-26T08:10:45.548281Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"@use_named_args(bayes_space)\ndef objective_function(**params):\n    hyperparams = {\n        \"learning_rate\": params[\"learning_rate\"],\n        \"dense_units_1\": params[\"dense_units_1\"],\n        \"dense_units_2\": params[\"dense_units_2\"],\n        \"dropout_rate_1\": params[\"dropout_rate_1\"],\n        \"dropout_rate_2\": params[\"dropout_rate_2\"],\n        \"unfreeze_layers\": params[\"unfreeze_layers\"]\n    }\n    \n    model_fn = ResNet50  # Change as needed\n    \n    model, base_model = build_tuned_model(model_fn, hyperparams, name=\"bayes_opt_model\")\n    \n    tuning_callbacks = [\n        EarlyStopping(monitor='val_auc', patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n    ]\n    \n    model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=5,\n        class_weight=class_weight_dict,\n        callbacks=tuning_callbacks,\n        verbose=0\n    )\n    \n    model = unfreeze_tuned_model(model, base_model, hyperparams)\n    model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=5,\n        class_weight=class_weight_dict,\n        callbacks=tuning_callbacks,\n        verbose=0\n    )\n    \n    val_results = model.evaluate(val_ds, verbose=0)\n    val_auc = val_results[model.metrics_names.index('auc')]\n    \n    return -val_auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:11:51.082934Z","iopub.execute_input":"2025-04-26T08:11:51.083590Z","iopub.status.idle":"2025-04-26T08:11:51.089608Z","shell.execute_reply.started":"2025-04-26T08:11:51.083559Z","shell.execute_reply":"2025-04-26T08:11:51.088777Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def run_bayesian_optimization(model_fn, n_calls=15):\n    print(f\"Starting Bayesian Optimization with {n_calls} iterations...\")\n    \n    result = gp_minimize(\n        objective_function,\n        bayes_space,\n        n_calls=n_calls,\n        n_random_starts=5,\n        verbose=True\n    )\n    \n    best_params = {\n        \"learning_rate\": result.x[0],\n        \"dense_units_1\": result.x[1],\n        \"dense_units_2\": result.x[2],\n        \"dropout_rate_1\": result.x[3],\n        \"dropout_rate_2\": result.x[4],\n        \"unfreeze_layers\": result.x[5]\n    }\n    \n    print(\"\\nBest parameters found:\")\n    for param, value in best_params.items():\n        print(f\"{param}: {value}\")\n    \n    print(f\"Best validation AUC: {-result.fun:.4f}\")\n    \n    return best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:12:29.662657Z","iopub.execute_input":"2025-04-26T08:12:29.662936Z","iopub.status.idle":"2025-04-26T08:12:29.669373Z","shell.execute_reply.started":"2025-04-26T08:12:29.662916Z","shell.execute_reply":"2025-04-26T08:12:29.668435Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def run_hyperparameter_optimization(model_fn, name, n_calls=15):\n    print(f\"\\n{'='*50}\")\n    print(f\"Bayesian optimization for {name}...\")\n    print(f\"{'='*50}\")\n    \n    best_params = run_bayesian_optimization(model_fn, n_calls=n_calls)\n    model, base_model = build_tuned_model(model_fn, best_params, name=f\"{name}_bayes_opt\")\n    \n    with open(f\"{name}_best_hyperparams.pkl\", \"wb\") as f:\n        pickle.dump(best_params, f)\n    print(f\"Saved hyperparameters: {name}_best_hyperparams.pkl\")\n    \n    return model, base_model, best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:17:58.950811Z","iopub.execute_input":"2025-04-26T08:17:58.951461Z","iopub.status.idle":"2025-04-26T08:17:58.956217Z","shell.execute_reply.started":"2025-04-26T08:17:58.951433Z","shell.execute_reply":"2025-04-26T08:17:58.955304Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def find_optimal_threshold(model, ds):\n    # Get predictions and true labels\n    pred = model.predict(ds)\n    true = np.concatenate([y for x, y in ds], axis=0)\n    \n    # Calculate ROC curve\n    fpr, tpr, thresholds = roc_curve(true, pred)\n    \n    # Find optimal threshold using Youden's J statistic\n    j_scores = tpr - fpr\n    optimal_idx = np.argmax(j_scores)\n    optimal_threshold = thresholds[optimal_idx]\n    \n    print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n    return optimal_threshold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:18:19.824179Z","iopub.execute_input":"2025-04-26T08:18:19.824477Z","iopub.status.idle":"2025-04-26T08:18:19.829598Z","shell.execute_reply.started":"2025-04-26T08:18:19.824443Z","shell.execute_reply":"2025-04-26T08:18:19.828695Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def evaluate_with_threshold(model, ds, threshold=0.5):\n    # Get predictions\n    pred = model.predict(ds)\n    \n    # Get true labels\n    true = np.concatenate([y for x, y in ds], axis=0)\n    \n    # Apply threshold\n    pred_binary = (pred > threshold).astype(int)\n    \n    # Calculate metrics\n    acc = accuracy_score(true, pred_binary)\n    auc = roc_auc_score(true, pred)\n    precision = precision_score(true, pred_binary)\n    recall = recall_score(true, pred_binary)\n    f1 = f1_score(true, pred_binary)\n    cm = confusion_matrix(true, pred_binary)\n    \n    # Calculate specificity\n    tn, fp, fn, tp = cm.ravel()\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    \n    print(f\"\\n{'='*30} Evaluation Results {'='*30}\")\n    print(f\"Accuracy: {acc:.4f}\")\n    print(f\"AUC: {auc:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall (Sensitivity): {recall:.4f}\")\n    print(f\"Specificity: {specificity:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"Confusion Matrix:\\n{cm}\")\n    print(f\"{'='*78}\")\n    \n    return {\n        'accuracy': acc,\n        'auc': auc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'confusion_matrix': cm,\n        'predictions': pred,\n        'threshold': threshold\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T08:19:14.633683Z","iopub.execute_input":"2025-04-26T08:19:14.633949Z","iopub.status.idle":"2025-04-26T08:19:14.640119Z","shell.execute_reply.started":"2025-04-26T08:19:14.633930Z","shell.execute_reply":"2025-04-26T08:19:14.639576Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# train_model_with_hyperopt function\ndef train_model_with_hyperopt(name, model_fn, n_calls=15):\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {name} with Bayesian optimization...\")\n    print(f\"{'='*50}\")\n    \n    model, base_model, best_params = run_hyperparameter_optimization(\n        model_fn, \n        name,\n        n_calls=n_calls\n    )\n    \n    callbacks = [\n        EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n        ModelCheckpoint(\n            f\"/kaggle/working/models/{name}_phase1.keras\",\n            save_best_only=True,\n            monitor='val_auc',\n            mode='max',\n            verbose=1\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]\n    \n    # Phase 1: Frozen base training\n    print(\"Initial training with frozen base layers...\")\n    history1 = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=30,\n        class_weight=class_weight_dict,\n        callbacks=callbacks,\n        verbose=2\n    )\n    \n    # Phase 2: Fine-tuning\n    print(\"\\nFine-tuning with unfrozen layers...\")\n    model = unfreeze_tuned_model(model, base_model, best_params)\n    callbacks[1] = ModelCheckpoint(\n        f\"/kaggle/working/models/{name}_phase2.keras\",\n        save_best_only=True,\n        monitor='val_auc',\n        mode='max',\n        verbose=1\n    )\n    \n    history2 = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=30,\n        class_weight=class_weight_dict,\n        callbacks=callbacks,\n        verbose=2\n    )\n    \n    # Threshold optimization and evaluation\n    print(\"\\nOptimizing classification threshold...\")\n    optimal_threshold = find_optimal_threshold(model, val_ds)\n    \n    print(\"\\nFinal evaluation on test set:\")\n    test_results = evaluate_with_threshold(model, test_ds, threshold=optimal_threshold)\n    \n    # Save model and results\n    model.save(f\"{name}_trained_model.h5\")\n    print(f\"Saved model: {name}_trained_model.h5\")\n    \n    combined_history = {\n        'phase1': history1.history,\n        'phase2': history2.history,\n        'best_hyperparams': best_params,\n        'test_results': test_results,\n        'optimal_threshold': optimal_threshold\n    }\n    \n    with open(f\"{name}_history.pkl\", \"wb\") as f:\n        pickle.dump(combined_history, f)\n    \n    return model, test_results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Update train_models_with_hyperopt to collect results\ndef train_models_with_hyperopt():\n    models_to_train = {\n        \"VGG16\": VGG16,\n        \"ResNet50\": ResNet50,\n        \"DenseNet121\": DenseNet121,\n        \"EfficientNetB3\": EfficientNetB3\n    }\n    \n    all_results = {}\n    \n    for name, model_fn in models_to_train.items():\n        model, results = train_model_with_hyperopt(\n            f\"{name}_BayesOpt\", \n            model_fn, \n            n_calls=15\n        )\n        all_results[f\"{name}_BayesOpt\"] = results\n    \n    with open(\"all_hyperopt_results.pkl\", \"wb\") as f:\n        pickle.dump(all_results, f)\n    \n    # Print summary of results\n    print(\"\\n\\n=== Final Results Summary ===\")\n    for model_name, results in all_results.items():\n        print(f\"\\n{model_name}:\")\n        print(f\"AUC: {results['auc']:.4f} | Accuracy: {results['accuracy']:.4f}\")\n        print(f\"Precision: {results['precision']:.4f} | Recall: {results['recall']:.4f}\")\n        print(f\"F1: {results['f1']:.4f} | Specificity: {results['specificity']:.4f}\")\n    \n    return all_results","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}