{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11420152,"sourceType":"datasetVersion","datasetId":7152221}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, EfficientNetB3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import KFold\nimport pickle\nimport collections\nfrom sklearn.metrics import (\n    accuracy_score, roc_auc_score, precision_score, recall_score,\n    f1_score, confusion_matrix, roc_curve\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:44:51.741823Z","iopub.execute_input":"2025-04-24T06:44:51.742296Z","iopub.status.idle":"2025-04-24T06:44:51.770597Z","shell.execute_reply.started":"2025-04-24T06:44:51.742267Z","shell.execute_reply":"2025-04-24T06:44:51.769830Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Use Mixed Precision (save VRAM)\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\nprint(\"mixed precision enabled.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:44:51.771418Z","iopub.execute_input":"2025-04-24T06:44:51.772080Z","iopub.status.idle":"2025-04-24T06:44:51.785328Z","shell.execute_reply.started":"2025-04-24T06:44:51.772061Z","shell.execute_reply":"2025-04-24T06:44:51.784752Z"}},"outputs":[{"name":"stdout","text":"mixed precision enabled.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load Preprocessed Data --- balanced checked\nDATA_PATH = \"/kaggle/input/preprocessed-mammo-splits\"  \ntrain = np.load(os.path.join(DATA_PATH, \"train_data.npz\"))\nval = np.load(os.path.join(DATA_PATH, \"val_data.npz\"))\ntest = np.load(os.path.join(DATA_PATH, \"test_data.npz\"))\n\nX_train, y_train = train[\"X\"], train[\"y\"]\nX_val, y_val = val[\"X\"], val[\"y\"]\nX_test, y_test = test[\"X\"], test[\"y\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:44:57.497973Z","iopub.execute_input":"2025-04-24T06:44:57.498295Z","iopub.status.idle":"2025-04-24T06:45:33.578749Z","shell.execute_reply.started":"2025-04-24T06:44:57.498271Z","shell.execute_reply":"2025-04-24T06:45:33.578021Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Compute Class Weights\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(zip(np.unique(y_train), class_weights))\nprint(\"Class Weights:\", class_weight_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:33.579809Z","iopub.execute_input":"2025-04-24T06:45:33.580072Z","iopub.status.idle":"2025-04-24T06:45:33.589216Z","shell.execute_reply.started":"2025-04-24T06:45:33.580051Z","shell.execute_reply":"2025-04-24T06:45:33.588486Z"}},"outputs":[{"name":"stdout","text":"Class Weights: {0: 1.1308917197452228, 1: 0.8962645128722867}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Expand dims because TF expects (H, W, 1) from (H, W)\nX_train = X_train[..., np.newaxis].astype(\"float32\")\nX_val = X_val[..., np.newaxis].astype(\"float32\")\nX_test = X_test[..., np.newaxis].astype(\"float32\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:33.589879Z","iopub.execute_input":"2025-04-24T06:45:33.590067Z","iopub.status.idle":"2025-04-24T06:45:35.523488Z","shell.execute_reply.started":"2025-04-24T06:45:33.590051Z","shell.execute_reply":"2025-04-24T06:45:35.522843Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Enhanced data augmentation\ndef convert_to_rgb(image, label):\n    image_rgb = tf.image.grayscale_to_rgb(image)  \n    image_rgb = tf.squeeze(image_rgb) \n    return image_rgb, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:35.525240Z","iopub.execute_input":"2025-04-24T06:45:35.525483Z","iopub.status.idle":"2025-04-24T06:45:35.529294Z","shell.execute_reply.started":"2025-04-24T06:45:35.525464Z","shell.execute_reply":"2025-04-24T06:45:35.528604Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def augment(image, label):\n    # Random rotation (0-15 degrees)\n    angle = tf.random.uniform([], -0.26, 0.26)  # ~15 degrees in radians\n    image = tf.image.rot90(image, k=tf.cast(angle * 2 / 3.14159, tf.int32))\n    \n    # Random flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    # Random brightness/contrast adjustments\n    image = tf.image.random_brightness(image, 0.2)\n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    \n    # Random zoom (crop and resize)\n    zoom_factor = tf.random.uniform([], 0.8, 1.0, dtype=tf.float32)\n    h, w = tf.shape(image)[0], tf.shape(image)[1]\n    crop_size_h = tf.cast(tf.cast(h, tf.float32) * zoom_factor, tf.int32)\n    crop_size_w = tf.cast(tf.cast(w, tf.float32) * zoom_factor, tf.int32)\n    \n    # Ensure crop dimensions don't exceed image dimensions\n    crop_size_h = tf.minimum(crop_size_h, h)\n    crop_size_w = tf.minimum(crop_size_w, w)\n    \n    image = tf.image.random_crop(image, size=[crop_size_h, crop_size_w, 3])\n    image = tf.image.resize(image, [224, 224])\n    \n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:35.529921Z","iopub.execute_input":"2025-04-24T06:45:35.530180Z","iopub.status.idle":"2025-04-24T06:45:35.545942Z","shell.execute_reply.started":"2025-04-24T06:45:35.530159Z","shell.execute_reply":"2025-04-24T06:45:35.545303Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"BATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Create datasets\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\ntest_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\n# Apply preprocessing and augmentation\ntrain_ds = (\n    train_ds.shuffle(1024)\n    .map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .map(augment, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\nval_ds = (\n    val_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)\n\ntest_ds = (\n    test_ds.map(convert_to_rgb, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTOTUNE)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:35.546749Z","iopub.execute_input":"2025-04-24T06:45:35.546998Z","iopub.status.idle":"2025-04-24T06:45:49.088141Z","shell.execute_reply.started":"2025-04-24T06:45:35.546975Z","shell.execute_reply":"2025-04-24T06:45:49.087561Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745477137.846102      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def build_improved_model(base_model_fn, name=\"model\", lr=1e-4):\n    base_model = base_model_fn(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n    # Initially freeze the base model\n    base_model.trainable = False\n    \n    inputs = Input(shape=(224, 224, 3))\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    \n    # Enhanced architecture with more layers\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    \n    outputs = Dense(1, activation='sigmoid', dtype='float32')(x)\n    \n    model = Model(inputs, outputs, name=name)\n\n    # Use simple float learning rate instead of schedule\n    model.compile(\n        optimizer=Adam(learning_rate=lr),  # Simple float learning rate\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy', \n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    \n    return model, base_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.088790Z","iopub.execute_input":"2025-04-24T06:45:49.088976Z","iopub.status.idle":"2025-04-24T06:45:49.095509Z","shell.execute_reply.started":"2025-04-24T06:45:49.088962Z","shell.execute_reply":"2025-04-24T06:45:49.094747Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# unfreeze_model function --- finetuning\ndef unfreeze_model(model, base_model, lr=1e-5):\n    # Unfreeze the base model\n    base_model.trainable = True\n    \n    # Freeze earlier layers, unfreeze later layers (fine-tuning)\n    for layer in base_model.layers[:-30]:  # Keep the first layers frozen\n        layer.trainable = False\n    \n    # Use simple float learning rate\n    model.compile(\n        optimizer=Adam(learning_rate=lr),  # Simple float learning rate\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy', \n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.096252Z","iopub.execute_input":"2025-04-24T06:45:49.096538Z","iopub.status.idle":"2025-04-24T06:45:49.115225Z","shell.execute_reply.started":"2025-04-24T06:45:49.096513Z","shell.execute_reply":"2025-04-24T06:45:49.114400Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Function to find the optimal threshold using the validation set\ndef find_optimal_threshold(model, val_ds):\n    # Get predictions\n    val_pred = model.predict(val_ds)\n    \n    # Get true labels\n    val_true = np.concatenate([y for x, y in val_ds], axis=0)\n    \n    # Calculate ROC curve and find optimal threshold\n    fpr, tpr, thresholds = roc_curve(val_true, val_pred)\n    j_scores = tpr - fpr\n    best_idx = np.argmax(j_scores)\n    best_threshold = thresholds[best_idx]\n    \n    print(f\"Optimal threshold: {best_threshold:.4f} (Youden's J = {j_scores[best_idx]:.4f})\")\n    print(f\"At threshold {best_threshold:.4f}: TPR={tpr[best_idx]:.4f}, FPR={fpr[best_idx]:.4f}\")\n    \n    return best_threshold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.115923Z","iopub.execute_input":"2025-04-24T06:45:49.116182Z","iopub.status.idle":"2025-04-24T06:45:49.131360Z","shell.execute_reply.started":"2025-04-24T06:45:49.116160Z","shell.execute_reply":"2025-04-24T06:45:49.130594Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def evaluate_with_threshold(model, ds, threshold=0.5):\n    # Get predictions\n    pred = model.predict(ds)\n    \n    # Get true labels\n    true = np.concatenate([y for x, y in ds], axis=0)\n    \n    # Apply threshold\n    pred_binary = (pred > threshold).astype(int)\n    \n    # Calculate metrics\n    acc = accuracy_score(true, pred_binary)\n    auc = roc_auc_score(true, pred)\n    precision = precision_score(true, pred_binary)\n    recall = recall_score(true, pred_binary)\n    f1 = f1_score(true, pred_binary)\n    cm = confusion_matrix(true, pred_binary)\n    \n    # Calculate specificity\n    tn, fp, fn, tp = cm.ravel()\n    specificity = tn / (tn + fp)\n    \n    print(f\"Accuracy: {acc:.4f}\")\n    print(f\"AUC: {auc:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall (Sensitivity): {recall:.4f}\")\n    print(f\"Specificity: {specificity:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"Confusion Matrix:\\n{cm}\")\n    \n    return {\n        'accuracy': acc,\n        'auc': auc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'confusion_matrix': cm,\n        'predictions': pred,\n        'threshold': threshold\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.133254Z","iopub.execute_input":"2025-04-24T06:45:49.133449Z","iopub.status.idle":"2025-04-24T06:45:49.152465Z","shell.execute_reply.started":"2025-04-24T06:45:49.133433Z","shell.execute_reply":"2025-04-24T06:45:49.151831Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Prepare Callbacks\nos.makedirs(\"/kaggle/working/models\", exist_ok=True)\n\ndef get_callbacks(name):\n    return [\n        # Stop training when validation loss doesn't improve for 15 epochs\n        EarlyStopping(\n            monitor='val_loss',\n            patience=15,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Save the best model during training\n        ModelCheckpoint(\n            f\"/kaggle/working/models/{name}.keras\",\n            save_best_only=True,\n            monitor='val_auc',\n            mode='max',\n            verbose=1\n        ),\n        # Reduce learning rate when validation loss plateaus\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.2,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.153082Z","iopub.execute_input":"2025-04-24T06:45:49.153320Z","iopub.status.idle":"2025-04-24T06:45:49.167620Z","shell.execute_reply.started":"2025-04-24T06:45:49.153302Z","shell.execute_reply":"2025-04-24T06:45:49.167045Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"models_to_train = {\n    \"VGG16\": VGG16\n    # \"ResNet50\": ResNet50\n    # \"DenseNet121\": DenseNet121,\n    # \"EfficientNetB3\": EfficientNetB3  \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.168196Z","iopub.execute_input":"2025-04-24T06:45:49.168400Z","iopub.status.idle":"2025-04-24T06:45:49.186028Z","shell.execute_reply.started":"2025-04-24T06:45:49.168386Z","shell.execute_reply":"2025-04-24T06:45:49.185340Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Store training histories and model results\nhistory_dict = {}\nmodel_results = {}\nall_trained_models = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.186928Z","iopub.execute_input":"2025-04-24T06:45:49.187180Z","iopub.status.idle":"2025-04-24T06:45:49.200533Z","shell.execute_reply.started":"2025-04-24T06:45:49.187158Z","shell.execute_reply":"2025-04-24T06:45:49.199856Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"for name, model_fn in models_to_train.items():\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {name}...\")\n    print(f\"{'='*50}\")\n    \n    # Build model\n    model, base_model = build_improved_model(model_fn, name=name)\n    \n    print(f\"Initial training with frozen base layers...\")\n    \n    # Phase 1: Train with frozen base model\n    history1 = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=30,  # Initial training epochs\n        class_weight=class_weight_dict,\n        callbacks=get_callbacks(f\"{name}_phase1\"),\n        verbose=2\n    )\n    \n    # Phase 2: Fine-tuning with unfrozen layers\n    print(f\"\\nFine-tuning with unfrozen layers...\")\n    model = unfreeze_model(model, base_model, lr=1e-5)\n    history2 = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=30,  # Fine-tuning epochs\n        class_weight=class_weight_dict,\n        callbacks=get_callbacks(f\"{name}_phase2\"),\n        verbose=2\n    )\n    \n    # Find optimal threshold\n    print(\"\\nFinding optimal threshold...\")\n    optimal_threshold = find_optimal_threshold(model, val_ds)\n    \n    # Evaluate model on test set with optimal threshold\n    print(\"\\nEvaluating on test set...\")\n    test_results = evaluate_with_threshold(model, test_ds, threshold=optimal_threshold)\n    model_results[name] = test_results\n    \n    # Save model\n    model.save(f\"{name}_trained_model.h5\")\n    print(f\"Saved model: {name}_trained_model.h5\")\n    \n    # Save training history\n    combined_history = {\n        'phase1': history1.history,\n        'phase2': history2.history\n    }\n    history_dict[name] = combined_history\n    with open(f\"{name}_history.pkl\", \"wb\") as f:\n        pickle.dump(combined_history, f)\n    print(f\"Saved training history: {name}_history.pkl\")\n    \n    # Store model for ensemble\n    all_trained_models[name] = model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:45:49.201193Z","iopub.execute_input":"2025-04-24T06:45:49.201354Z","iopub.status.idle":"2025-04-24T08:12:02.896316Z","shell.execute_reply.started":"2025-04-24T06:45:49.201342Z","shell.execute_reply":"2025-04-24T08:12:02.895606Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nTraining VGG16...\n==================================================\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nInitial training with frozen base layers...\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1745477158.907513      89 service.cc:148] XLA service 0x7a76700060e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1745477158.908277      89 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1745477159.649324      89 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1745477170.933685      89 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_auc improved from -inf to 0.88971, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 86s - 156ms/step - accuracy: 0.6537 - auc: 0.7159 - loss: 0.6698 - precision: 0.7036 - recall: 0.6553 - val_accuracy: 0.7920 - val_auc: 0.8897 - val_loss: 0.4300 - val_precision: 0.7663 - val_recall: 0.9022 - learning_rate: 1.0000e-04\nEpoch 2/30\n\nEpoch 2: val_auc improved from 0.88971 to 0.90911, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 48s - 86ms/step - accuracy: 0.7406 - auc: 0.8215 - loss: 0.5277 - precision: 0.7797 - recall: 0.7459 - val_accuracy: 0.8108 - val_auc: 0.9091 - val_loss: 0.3701 - val_precision: 0.8151 - val_recall: 0.8547 - learning_rate: 1.0000e-04\nEpoch 3/30\n\nEpoch 3: val_auc improved from 0.90911 to 0.92242, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.7598 - auc: 0.8497 - loss: 0.4858 - precision: 0.7973 - recall: 0.7636 - val_accuracy: 0.8248 - val_auc: 0.9224 - val_loss: 0.3510 - val_precision: 0.8627 - val_recall: 0.8158 - learning_rate: 1.0000e-04\nEpoch 4/30\n\nEpoch 4: val_auc improved from 0.92242 to 0.92298, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 48s - 86ms/step - accuracy: 0.7814 - auc: 0.8721 - loss: 0.4471 - precision: 0.8160 - recall: 0.7853 - val_accuracy: 0.8283 - val_auc: 0.9230 - val_loss: 0.3409 - val_precision: 0.8292 - val_recall: 0.8719 - learning_rate: 1.0000e-04\nEpoch 5/30\n\nEpoch 5: val_auc improved from 0.92298 to 0.93171, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.7875 - auc: 0.8781 - loss: 0.4375 - precision: 0.8207 - recall: 0.7921 - val_accuracy: 0.8366 - val_auc: 0.9317 - val_loss: 0.3294 - val_precision: 0.8778 - val_recall: 0.8215 - learning_rate: 1.0000e-04\nEpoch 6/30\n\nEpoch 6: val_auc improved from 0.93171 to 0.93828, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 48s - 86ms/step - accuracy: 0.8016 - auc: 0.8922 - loss: 0.4112 - precision: 0.8323 - recall: 0.8070 - val_accuracy: 0.8440 - val_auc: 0.9383 - val_loss: 0.3271 - val_precision: 0.9069 - val_recall: 0.8026 - learning_rate: 1.0000e-04\nEpoch 7/30\n\nEpoch 7: val_auc improved from 0.93828 to 0.93923, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8104 - auc: 0.8990 - loss: 0.3987 - precision: 0.8420 - recall: 0.8126 - val_accuracy: 0.8491 - val_auc: 0.9392 - val_loss: 0.3157 - val_precision: 0.8847 - val_recall: 0.8387 - learning_rate: 1.0000e-04\nEpoch 8/30\n\nEpoch 8: val_auc improved from 0.93923 to 0.94254, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 86ms/step - accuracy: 0.8138 - auc: 0.9042 - loss: 0.3877 - precision: 0.8437 - recall: 0.8177 - val_accuracy: 0.8551 - val_auc: 0.9425 - val_loss: 0.3018 - val_precision: 0.8884 - val_recall: 0.8467 - learning_rate: 1.0000e-04\nEpoch 9/30\n\nEpoch 9: val_auc improved from 0.94254 to 0.94488, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 86ms/step - accuracy: 0.8155 - auc: 0.9070 - loss: 0.3823 - precision: 0.8469 - recall: 0.8170 - val_accuracy: 0.8583 - val_auc: 0.9449 - val_loss: 0.2943 - val_precision: 0.8849 - val_recall: 0.8576 - learning_rate: 1.0000e-04\nEpoch 10/30\n\nEpoch 10: val_auc improved from 0.94488 to 0.94952, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8191 - auc: 0.9089 - loss: 0.3780 - precision: 0.8487 - recall: 0.8223 - val_accuracy: 0.8567 - val_auc: 0.9495 - val_loss: 0.2922 - val_precision: 0.9037 - val_recall: 0.8318 - learning_rate: 1.0000e-04\nEpoch 11/30\n\nEpoch 11: val_auc did not improve from 0.94952\n555/555 - 47s - 85ms/step - accuracy: 0.8292 - auc: 0.9158 - loss: 0.3648 - precision: 0.8593 - recall: 0.8296 - val_accuracy: 0.8660 - val_auc: 0.9478 - val_loss: 0.2902 - val_precision: 0.8976 - val_recall: 0.8576 - learning_rate: 1.0000e-04\nEpoch 12/30\n\nEpoch 12: val_auc did not improve from 0.94952\n555/555 - 47s - 85ms/step - accuracy: 0.8306 - auc: 0.9191 - loss: 0.3569 - precision: 0.8587 - recall: 0.8335 - val_accuracy: 0.8618 - val_auc: 0.9490 - val_loss: 0.2842 - val_precision: 0.8575 - val_recall: 0.9022 - learning_rate: 1.0000e-04\nEpoch 13/30\n\nEpoch 13: val_auc improved from 0.94952 to 0.95329, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8338 - auc: 0.9237 - loss: 0.3463 - precision: 0.8618 - recall: 0.8361 - val_accuracy: 0.8631 - val_auc: 0.9533 - val_loss: 0.2858 - val_precision: 0.9247 - val_recall: 0.8215 - learning_rate: 1.0000e-04\nEpoch 14/30\n\nEpoch 14: val_auc improved from 0.95329 to 0.95360, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8355 - auc: 0.9231 - loss: 0.3489 - precision: 0.8646 - recall: 0.8360 - val_accuracy: 0.8698 - val_auc: 0.9536 - val_loss: 0.2742 - val_precision: 0.9022 - val_recall: 0.8598 - learning_rate: 1.0000e-04\nEpoch 15/30\n\nEpoch 15: val_auc improved from 0.95360 to 0.95367, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8372 - auc: 0.9259 - loss: 0.3421 - precision: 0.8691 - recall: 0.8337 - val_accuracy: 0.8647 - val_auc: 0.9537 - val_loss: 0.2705 - val_precision: 0.8757 - val_recall: 0.8827 - learning_rate: 1.0000e-04\nEpoch 16/30\n\nEpoch 16: val_auc improved from 0.95367 to 0.95704, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8411 - auc: 0.9277 - loss: 0.3384 - precision: 0.8699 - recall: 0.8410 - val_accuracy: 0.8692 - val_auc: 0.9570 - val_loss: 0.2775 - val_precision: 0.9267 - val_recall: 0.8312 - learning_rate: 1.0000e-04\nEpoch 17/30\n\nEpoch 17: val_auc did not improve from 0.95704\n555/555 - 47s - 85ms/step - accuracy: 0.8443 - auc: 0.9293 - loss: 0.3355 - precision: 0.8727 - recall: 0.8440 - val_accuracy: 0.8724 - val_auc: 0.9540 - val_loss: 0.2794 - val_precision: 0.9135 - val_recall: 0.8518 - learning_rate: 1.0000e-04\nEpoch 18/30\n\nEpoch 18: val_auc improved from 0.95704 to 0.95775, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8455 - auc: 0.9314 - loss: 0.3301 - precision: 0.8726 - recall: 0.8466 - val_accuracy: 0.8711 - val_auc: 0.9578 - val_loss: 0.2743 - val_precision: 0.9319 - val_recall: 0.8295 - learning_rate: 1.0000e-04\nEpoch 19/30\n\nEpoch 19: val_auc improved from 0.95775 to 0.95977, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 86ms/step - accuracy: 0.8453 - auc: 0.9339 - loss: 0.3233 - precision: 0.8724 - recall: 0.8466 - val_accuracy: 0.8720 - val_auc: 0.9598 - val_loss: 0.2604 - val_precision: 0.9145 - val_recall: 0.8501 - learning_rate: 1.0000e-04\nEpoch 20/30\n\nEpoch 20: val_auc improved from 0.95977 to 0.96163, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 86ms/step - accuracy: 0.8510 - auc: 0.9359 - loss: 0.3183 - precision: 0.8778 - recall: 0.8514 - val_accuracy: 0.8756 - val_auc: 0.9616 - val_loss: 0.2536 - val_precision: 0.9166 - val_recall: 0.8547 - learning_rate: 1.0000e-04\nEpoch 21/30\n\nEpoch 21: val_auc did not improve from 0.96163\n555/555 - 47s - 85ms/step - accuracy: 0.8500 - auc: 0.9349 - loss: 0.3218 - precision: 0.8798 - recall: 0.8467 - val_accuracy: 0.8740 - val_auc: 0.9605 - val_loss: 0.2569 - val_precision: 0.9128 - val_recall: 0.8558 - learning_rate: 1.0000e-04\nEpoch 22/30\n\nEpoch 22: val_auc improved from 0.96163 to 0.96342, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8503 - auc: 0.9361 - loss: 0.3197 - precision: 0.8795 - recall: 0.8479 - val_accuracy: 0.8743 - val_auc: 0.9634 - val_loss: 0.2657 - val_precision: 0.9431 - val_recall: 0.8244 - learning_rate: 1.0000e-04\nEpoch 23/30\n\nEpoch 23: val_auc did not improve from 0.96342\n555/555 - 47s - 85ms/step - accuracy: 0.8534 - auc: 0.9372 - loss: 0.3161 - precision: 0.8822 - recall: 0.8509 - val_accuracy: 0.8752 - val_auc: 0.9604 - val_loss: 0.2523 - val_precision: 0.8726 - val_recall: 0.9090 - learning_rate: 1.0000e-04\nEpoch 24/30\n\nEpoch 24: val_auc did not improve from 0.96342\n555/555 - 47s - 85ms/step - accuracy: 0.8542 - auc: 0.9397 - loss: 0.3099 - precision: 0.8817 - recall: 0.8532 - val_accuracy: 0.8816 - val_auc: 0.9633 - val_loss: 0.2469 - val_precision: 0.9160 - val_recall: 0.8673 - learning_rate: 1.0000e-04\nEpoch 25/30\n\nEpoch 25: val_auc did not improve from 0.96342\n555/555 - 47s - 85ms/step - accuracy: 0.8609 - auc: 0.9429 - loss: 0.3020 - precision: 0.8876 - recall: 0.8595 - val_accuracy: 0.8813 - val_auc: 0.9621 - val_loss: 0.2451 - val_precision: 0.8814 - val_recall: 0.9096 - learning_rate: 1.0000e-04\nEpoch 26/30\n\nEpoch 26: val_auc improved from 0.96342 to 0.96778, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8629 - auc: 0.9443 - loss: 0.2985 - precision: 0.8904 - recall: 0.8602 - val_accuracy: 0.8890 - val_auc: 0.9678 - val_loss: 0.2429 - val_precision: 0.9425 - val_recall: 0.8530 - learning_rate: 1.0000e-04\nEpoch 27/30\n\nEpoch 27: val_auc improved from 0.96778 to 0.96809, saving model to /kaggle/working/models/VGG16_phase1.keras\n555/555 - 47s - 85ms/step - accuracy: 0.8598 - auc: 0.9423 - loss: 0.3037 - precision: 0.8873 - recall: 0.8575 - val_accuracy: 0.8778 - val_auc: 0.9681 - val_loss: 0.2577 - val_precision: 0.9571 - val_recall: 0.8175 - learning_rate: 1.0000e-04\nEpoch 28/30\n\nEpoch 28: val_auc did not improve from 0.96809\n555/555 - 47s - 85ms/step - accuracy: 0.8638 - auc: 0.9459 - loss: 0.2939 - precision: 0.8917 - recall: 0.8603 - val_accuracy: 0.8890 - val_auc: 0.9635 - val_loss: 0.2406 - val_precision: 0.8968 - val_recall: 0.9050 - learning_rate: 1.0000e-04\nEpoch 29/30\n\nEpoch 29: val_auc did not improve from 0.96809\n555/555 - 47s - 85ms/step - accuracy: 0.8662 - auc: 0.9459 - loss: 0.2947 - precision: 0.8935 - recall: 0.8630 - val_accuracy: 0.8950 - val_auc: 0.9673 - val_loss: 0.2325 - val_precision: 0.9171 - val_recall: 0.8924 - learning_rate: 1.0000e-04\nEpoch 30/30\n\nEpoch 30: val_auc did not improve from 0.96809\n555/555 - 47s - 85ms/step - accuracy: 0.8691 - auc: 0.9480 - loss: 0.2896 - precision: 0.8952 - recall: 0.8668 - val_accuracy: 0.8925 - val_auc: 0.9670 - val_loss: 0.2337 - val_precision: 0.9162 - val_recall: 0.8884 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 29.\n\nFine-tuning with unfrozen layers...\nEpoch 1/30\n\nEpoch 1: val_auc improved from -inf to 0.96705, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 190s - 342ms/step - accuracy: 0.8696 - auc: 0.9490 - loss: 0.2876 - precision: 0.8957 - recall: 0.8672 - val_accuracy: 0.8995 - val_auc: 0.9671 - val_loss: 0.2288 - val_precision: 0.8930 - val_recall: 0.9314 - learning_rate: 1.0000e-05\nEpoch 2/30\n\nEpoch 2: val_auc improved from 0.96705 to 0.98389, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9072 - auc: 0.9712 - loss: 0.2170 - precision: 0.9335 - recall: 0.8976 - val_accuracy: 0.9078 - val_auc: 0.9839 - val_loss: 0.1996 - val_precision: 0.8690 - val_recall: 0.9828 - learning_rate: 1.0000e-05\nEpoch 3/30\n\nEpoch 3: val_auc improved from 0.98389 to 0.99399, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9320 - auc: 0.9832 - loss: 0.1682 - precision: 0.9541 - recall: 0.9226 - val_accuracy: 0.9560 - val_auc: 0.9940 - val_loss: 0.1172 - val_precision: 0.9849 - val_recall: 0.9354 - learning_rate: 1.0000e-05\nEpoch 4/30\n\nEpoch 4: val_auc improved from 0.99399 to 0.99816, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9513 - auc: 0.9908 - loss: 0.1261 - precision: 0.9672 - recall: 0.9448 - val_accuracy: 0.9777 - val_auc: 0.9982 - val_loss: 0.0711 - val_precision: 0.9833 - val_recall: 0.9765 - learning_rate: 1.0000e-05\nEpoch 5/30\n\nEpoch 5: val_auc improved from 0.99816 to 0.99895, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9700 - auc: 0.9958 - loss: 0.0898 - precision: 0.9804 - recall: 0.9656 - val_accuracy: 0.9757 - val_auc: 0.9989 - val_loss: 0.0703 - val_precision: 0.9982 - val_recall: 0.9582 - learning_rate: 1.0000e-05\nEpoch 6/30\n\nEpoch 6: val_auc did not improve from 0.99895\n555/555 - 120s - 215ms/step - accuracy: 0.9756 - auc: 0.9971 - loss: 0.0743 - precision: 0.9830 - recall: 0.9730 - val_accuracy: 0.9812 - val_auc: 0.9989 - val_loss: 0.0536 - val_precision: 0.9715 - val_recall: 0.9954 - learning_rate: 1.0000e-05\nEpoch 7/30\n\nEpoch 7: val_auc improved from 0.99895 to 0.99986, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9802 - auc: 0.9982 - loss: 0.0606 - precision: 0.9873 - recall: 0.9770 - val_accuracy: 0.9892 - val_auc: 0.9999 - val_loss: 0.0371 - val_precision: 0.9983 - val_recall: 0.9823 - learning_rate: 1.0000e-05\nEpoch 8/30\n\nEpoch 8: val_auc did not improve from 0.99986\n555/555 - 120s - 215ms/step - accuracy: 0.9864 - auc: 0.9990 - loss: 0.0463 - precision: 0.9908 - recall: 0.9849 - val_accuracy: 0.9866 - val_auc: 0.9996 - val_loss: 0.0406 - val_precision: 0.9776 - val_recall: 0.9989 - learning_rate: 1.0000e-05\nEpoch 9/30\n\nEpoch 9: val_auc did not improve from 0.99986\n555/555 - 120s - 215ms/step - accuracy: 0.9863 - auc: 0.9988 - loss: 0.0449 - precision: 0.9905 - recall: 0.9850 - val_accuracy: 0.9604 - val_auc: 0.9990 - val_loss: 0.0958 - val_precision: 0.9342 - val_recall: 0.9994 - learning_rate: 1.0000e-05\nEpoch 10/30\n\nEpoch 10: val_auc improved from 0.99986 to 0.99998, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9887 - auc: 0.9992 - loss: 0.0392 - precision: 0.9921 - recall: 0.9876 - val_accuracy: 0.9968 - val_auc: 1.0000 - val_loss: 0.0130 - val_precision: 0.9943 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 11/30\n\nEpoch 11: val_auc did not improve from 0.99998\n555/555 - 120s - 216ms/step - accuracy: 0.9892 - auc: 0.9993 - loss: 0.0345 - precision: 0.9919 - recall: 0.9888 - val_accuracy: 0.9888 - val_auc: 0.9997 - val_loss: 0.0324 - val_precision: 0.9825 - val_recall: 0.9977 - learning_rate: 1.0000e-05\nEpoch 12/30\n\nEpoch 12: val_auc did not improve from 0.99998\n555/555 - 120s - 216ms/step - accuracy: 0.9932 - auc: 0.9995 - loss: 0.0273 - precision: 0.9957 - recall: 0.9921 - val_accuracy: 0.9920 - val_auc: 0.9997 - val_loss: 0.0270 - val_precision: 0.9881 - val_recall: 0.9977 - learning_rate: 1.0000e-05\nEpoch 13/30\n\nEpoch 13: val_auc improved from 0.99998 to 1.00000, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9919 - auc: 0.9995 - loss: 0.0287 - precision: 0.9943 - recall: 0.9911 - val_accuracy: 0.9968 - val_auc: 1.0000 - val_loss: 0.0126 - val_precision: 0.9943 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 14/30\n\nEpoch 14: val_auc did not improve from 1.00000\n555/555 - 120s - 216ms/step - accuracy: 0.9892 - auc: 0.9991 - loss: 0.0339 - precision: 0.9924 - recall: 0.9883 - val_accuracy: 0.9959 - val_auc: 0.9999 - val_loss: 0.0154 - val_precision: 0.9966 - val_recall: 0.9960 - learning_rate: 1.0000e-05\nEpoch 15/30\n\nEpoch 15: val_auc did not improve from 1.00000\n555/555 - 120s - 216ms/step - accuracy: 0.9930 - auc: 0.9995 - loss: 0.0249 - precision: 0.9954 - recall: 0.9920 - val_accuracy: 0.9962 - val_auc: 0.9999 - val_loss: 0.0152 - val_precision: 0.9932 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 16/30\n\nEpoch 16: val_auc did not improve from 1.00000\n555/555 - 120s - 216ms/step - accuracy: 0.9929 - auc: 0.9997 - loss: 0.0237 - precision: 0.9953 - recall: 0.9919 - val_accuracy: 0.9965 - val_auc: 0.9999 - val_loss: 0.0140 - val_precision: 0.9971 - val_recall: 0.9966 - learning_rate: 1.0000e-05\nEpoch 17/30\n\nEpoch 17: val_auc did not improve from 1.00000\n555/555 - 120s - 216ms/step - accuracy: 0.9917 - auc: 0.9995 - loss: 0.0259 - precision: 0.9942 - recall: 0.9908 - val_accuracy: 0.9987 - val_auc: 1.0000 - val_loss: 0.0075 - val_precision: 1.0000 - val_recall: 0.9977 - learning_rate: 1.0000e-05\nEpoch 18/30\n\nEpoch 18: val_auc improved from 1.00000 to 1.00000, saving model to /kaggle/working/models/VGG16_phase2.keras\n555/555 - 121s - 218ms/step - accuracy: 0.9949 - auc: 0.9998 - loss: 0.0187 - precision: 0.9966 - recall: 0.9942 - val_accuracy: 0.9965 - val_auc: 1.0000 - val_loss: 0.0118 - val_precision: 1.0000 - val_recall: 0.9937 - learning_rate: 1.0000e-05\nEpoch 19/30\n\nEpoch 19: val_auc did not improve from 1.00000\n555/555 - 119s - 215ms/step - accuracy: 0.9948 - auc: 0.9997 - loss: 0.0192 - precision: 0.9958 - recall: 0.9949 - val_accuracy: 0.9965 - val_auc: 1.0000 - val_loss: 0.0090 - val_precision: 0.9937 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 20/30\n\nEpoch 20: val_auc did not improve from 1.00000\n555/555 - 120s - 215ms/step - accuracy: 0.9941 - auc: 0.9997 - loss: 0.0197 - precision: 0.9954 - recall: 0.9941 - val_accuracy: 0.9997 - val_auc: 1.0000 - val_loss: 0.0039 - val_precision: 0.9994 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 21/30\n\nEpoch 21: val_auc did not improve from 1.00000\n555/555 - 120s - 215ms/step - accuracy: 0.9950 - auc: 0.9996 - loss: 0.0174 - precision: 0.9969 - recall: 0.9942 - val_accuracy: 0.9936 - val_auc: 0.9996 - val_loss: 0.0186 - val_precision: 0.9887 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 22/30\n\nEpoch 22: val_auc did not improve from 1.00000\n555/555 - 120s - 215ms/step - accuracy: 0.9938 - auc: 0.9996 - loss: 0.0205 - precision: 0.9948 - recall: 0.9940 - val_accuracy: 0.9997 - val_auc: 1.0000 - val_loss: 0.0020 - val_precision: 0.9994 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 23/30\n\nEpoch 23: val_auc did not improve from 1.00000\n555/555 - 120s - 216ms/step - accuracy: 0.9949 - auc: 0.9998 - loss: 0.0155 - precision: 0.9965 - recall: 0.9943 - val_accuracy: 0.9920 - val_auc: 1.0000 - val_loss: 0.0187 - val_precision: 0.9864 - val_recall: 0.9994 - learning_rate: 1.0000e-05\nEpoch 24/30\n\nEpoch 24: val_auc did not improve from 1.00000\n555/555 - 119s - 215ms/step - accuracy: 0.9961 - auc: 0.9998 - loss: 0.0136 - precision: 0.9975 - recall: 0.9955 - val_accuracy: 0.9962 - val_auc: 1.0000 - val_loss: 0.0108 - val_precision: 0.9932 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 25/30\n\nEpoch 25: val_auc did not improve from 1.00000\n555/555 - 120s - 215ms/step - accuracy: 0.9954 - auc: 0.9998 - loss: 0.0151 - precision: 0.9968 - recall: 0.9951 - val_accuracy: 0.9997 - val_auc: 1.0000 - val_loss: 0.0023 - val_precision: 1.0000 - val_recall: 0.9994 - learning_rate: 1.0000e-05\nEpoch 26/30\n\nEpoch 26: val_auc did not improve from 1.00000\n555/555 - 119s - 215ms/step - accuracy: 0.9961 - auc: 0.9998 - loss: 0.0138 - precision: 0.9974 - recall: 0.9957 - val_accuracy: 0.9971 - val_auc: 1.0000 - val_loss: 0.0120 - val_precision: 0.9949 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 27/30\n\nEpoch 27: val_auc did not improve from 1.00000\n\nEpoch 27: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n555/555 - 142s - 256ms/step - accuracy: 0.9959 - auc: 0.9999 - loss: 0.0148 - precision: 0.9967 - recall: 0.9960 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\nEpoch 28/30\n\nEpoch 28: val_auc did not improve from 1.00000\n555/555 - 120s - 215ms/step - accuracy: 0.9990 - auc: 1.0000 - loss: 0.0054 - precision: 0.9992 - recall: 0.9991 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 7.9499e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\nEpoch 29/30\n\nEpoch 29: val_auc did not improve from 1.00000\n555/555 - 120s - 216ms/step - accuracy: 0.9990 - auc: 1.0000 - loss: 0.0051 - precision: 0.9991 - recall: 0.9992 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 5.5587e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\nEpoch 30/30\n\nEpoch 30: val_auc did not improve from 1.00000\n555/555 - 120s - 215ms/step - accuracy: 0.9989 - auc: 1.0000 - loss: 0.0049 - precision: 0.9990 - recall: 0.9990 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 6.3590e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\nRestoring model weights from the end of the best epoch: 29.\n\nFinding optimal threshold...\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step\nOptimal threshold: 0.8526 (Youden's J = 1.0000)\nAt threshold 0.8526: TPR=1.0000, FPR=0.0000\n\nEvaluating on test set...\n\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step\nAccuracy: 0.9997\nAUC: 1.0000\nPrecision: 1.0000\nRecall (Sensitivity): 0.9995\nSpecificity: 1.0000\nF1 Score: 0.9998\nConfusion Matrix:\n[[1630    0]\n [   1 2056]]\nSaved model: VGG16_trained_model.h5\nSaved training history: VGG16_history.pkl\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}